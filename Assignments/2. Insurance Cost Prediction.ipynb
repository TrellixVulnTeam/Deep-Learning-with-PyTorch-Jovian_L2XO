{"cells":[{"cell_type":"markdown","metadata":{"id":"fXIxCI5E-yLo"},"source":["# Insurance cost prediction using linear regression\n","\n","Make a submisson here: https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans/assignment/assignment-2-train-your-first-model\n","\n","In this assignment we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from [Kaggle](https://www.kaggle.com/mirichoi0218/insurance).\n","\n","\n","We will create a model with the following steps:\n","1. Download and explore the dataset\n","2. Prepare the dataset for training\n","3. Create a linear regression model\n","4. Train the model to fit the data\n","5. Make predictions using the trained model\n","\n","\n","This assignment builds upon the concepts from the first 2 lessons. It will help to review these Jupyter notebooks:\n","- PyTorch basics: https://jovian.ai/aakashns/01-pytorch-basics\n","- Linear Regression: https://jovian.ai/aakashns/02-linear-regression\n","- Logistic Regression: https://jovian.ai/aakashns/03-logistic-regression\n","- Linear regression (minimal): https://jovian.ai/aakashns/housing-linear-minimal\n","- Logistic regression (minimal): https://jovian.ai/aakashns/mnist-logistic-minimal\n","\n","As you go through this notebook, you will find a **???** in certain places. Your job is to replace the **???** with appropriate code or values, to ensure that the notebook runs properly end-to-end . In some cases, you'll be required to choose some hyperparameters (learning rate, batch size etc.). Try to experiment with the hypeparameters to get the lowest loss.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TYsiDeOc-yL0"},"outputs":[],"source":["# Uncomment and run the appropriate command for your operating system, if required\n","\n","# Linux / Binder\n","# !pip install numpy matplotlib pandas torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n","\n","# Windows\n","# !pip install numpy matplotlib pandas torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n","\n","# MacOS\n","# !pip install numpy matplotlib pandas torch torchvision torchaudio"]},{"cell_type":"code","execution_count":173,"metadata":{"id":"aok8GAPo_ek-","executionInfo":{"status":"ok","timestamp":1649779224925,"user_tz":-60,"elapsed":4000,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["!pip install jovian --upgrade --quiet"]},{"cell_type":"code","execution_count":174,"metadata":{"id":"ssC4gu8T-yL3","executionInfo":{"status":"ok","timestamp":1649779224927,"user_tz":-60,"elapsed":47,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["import torch\n","import jovian\n","import torchvision\n","import torch.nn as nn\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","from torchvision.datasets.utils import download_url\n","from torch.utils.data import DataLoader, TensorDataset, random_split"]},{"cell_type":"code","execution_count":175,"metadata":{"id":"tSNn9mqD-yL5","executionInfo":{"status":"ok","timestamp":1649779224929,"user_tz":-60,"elapsed":48,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["project_name='02-insurance-linear-regression' # will be used by jovian.commit"]},{"cell_type":"markdown","metadata":{"id":"orx9gL4W-yL6"},"source":["## Step 1: Download and explore the data\n","\n","Let us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. "]},{"cell_type":"code","execution_count":176,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48,"status":"ok","timestamp":1649779224930,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"dESuXpT--yL7","outputId":"c657610f-19fc-462b-e243-9a8534680159"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using downloaded and verified file: ./insurance.csv\n"]}],"source":["DATASET_URL = \"https://gist.github.com/BirajCoder/5f068dfe759c1ea6bdfce9535acdb72d/raw/c84d84e3c80f93be67f6c069cbdc0195ec36acbd/insurance.csv\"\n","DATA_FILENAME = \"insurance.csv\"\n","download_url(DATASET_URL, '.')"]},{"cell_type":"markdown","metadata":{"id":"eJxE-kJs-yL9"},"source":["To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/"]},{"cell_type":"code","execution_count":177,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1649779224933,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"y5VnBY55-yL-","outputId":"89a8cb6a-c207-40ce-d8d1-9bb320c64d72"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   age     sex     bmi  children smoker     region      charges\n","0   19  female  27.900         0    yes  southwest  16884.92400\n","1   18    male  33.770         1     no  southeast   1725.55230\n","2   28    male  33.000         3     no  southeast   4449.46200\n","3   33    male  22.705         0     no  northwest  21984.47061\n","4   32    male  28.880         0     no  northwest   3866.85520"],"text/html":["\n","  <div id=\"df-ed022c27-0ce6-4195-bf66-764b7196fb0f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>bmi</th>\n","      <th>children</th>\n","      <th>smoker</th>\n","      <th>region</th>\n","      <th>charges</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>19</td>\n","      <td>female</td>\n","      <td>27.900</td>\n","      <td>0</td>\n","      <td>yes</td>\n","      <td>southwest</td>\n","      <td>16884.92400</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>18</td>\n","      <td>male</td>\n","      <td>33.770</td>\n","      <td>1</td>\n","      <td>no</td>\n","      <td>southeast</td>\n","      <td>1725.55230</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>28</td>\n","      <td>male</td>\n","      <td>33.000</td>\n","      <td>3</td>\n","      <td>no</td>\n","      <td>southeast</td>\n","      <td>4449.46200</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>33</td>\n","      <td>male</td>\n","      <td>22.705</td>\n","      <td>0</td>\n","      <td>no</td>\n","      <td>northwest</td>\n","      <td>21984.47061</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>32</td>\n","      <td>male</td>\n","      <td>28.880</td>\n","      <td>0</td>\n","      <td>no</td>\n","      <td>northwest</td>\n","      <td>3866.85520</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed022c27-0ce6-4195-bf66-764b7196fb0f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ed022c27-0ce6-4195-bf66-764b7196fb0f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ed022c27-0ce6-4195-bf66-764b7196fb0f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":177}],"source":["dataframe_raw = pd.read_csv(DATA_FILENAME)\n","dataframe_raw.head()"]},{"cell_type":"markdown","metadata":{"id":"EzblA2AW-yMA"},"source":["We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. Fill in your name below as a string (enter at least 5 characters)"]},{"cell_type":"code","execution_count":178,"metadata":{"id":"PWFVHuEg-yMB","executionInfo":{"status":"ok","timestamp":1649779224934,"user_tz":-60,"elapsed":42,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["your_name = \"Daniel\" # at least 5 characters"]},{"cell_type":"markdown","metadata":{"id":"tEp1b3UQ-yMB"},"source":["The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers."]},{"cell_type":"code","execution_count":179,"metadata":{"id":"np5IitEp-yMC","executionInfo":{"status":"ok","timestamp":1649779226889,"user_tz":-60,"elapsed":12,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["def customize_dataset(dataframe_raw, rand_str):\n","    dataframe = dataframe_raw.copy(deep=True)\n","    # drop some rows\n","    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n","    # scale input\n","    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n","    # scale target\n","    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n","    # drop column\n","    if ord(rand_str[3]) % 2 == 1:\n","        dataframe = dataframe.drop(['region'], axis=1)\n","    return dataframe"]},{"cell_type":"code","execution_count":180,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1649779226891,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"BstHyiZF-yMD","outputId":"e8f42617-ae3d-4587-92a1-95dccfe7b07d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["      age     sex       bmi  children smoker       charges\n","184    44    male  29.76930         2     no   8504.569810\n","378    64  female  29.21155         3     no  18101.278635\n","1179   31    male  28.91570         0    yes  21285.405790\n","55     58    male  35.84635         2    yes  52246.143895\n","121    18    male  23.03750         0     no   1876.186950"],"text/html":["\n","  <div id=\"df-3f713b4e-3b17-497b-974c-9214aad0b0e3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>bmi</th>\n","      <th>children</th>\n","      <th>smoker</th>\n","      <th>charges</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>184</th>\n","      <td>44</td>\n","      <td>male</td>\n","      <td>29.76930</td>\n","      <td>2</td>\n","      <td>no</td>\n","      <td>8504.569810</td>\n","    </tr>\n","    <tr>\n","      <th>378</th>\n","      <td>64</td>\n","      <td>female</td>\n","      <td>29.21155</td>\n","      <td>3</td>\n","      <td>no</td>\n","      <td>18101.278635</td>\n","    </tr>\n","    <tr>\n","      <th>1179</th>\n","      <td>31</td>\n","      <td>male</td>\n","      <td>28.91570</td>\n","      <td>0</td>\n","      <td>yes</td>\n","      <td>21285.405790</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>58</td>\n","      <td>male</td>\n","      <td>35.84635</td>\n","      <td>2</td>\n","      <td>yes</td>\n","      <td>52246.143895</td>\n","    </tr>\n","    <tr>\n","      <th>121</th>\n","      <td>18</td>\n","      <td>male</td>\n","      <td>23.03750</td>\n","      <td>0</td>\n","      <td>no</td>\n","      <td>1876.186950</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f713b4e-3b17-497b-974c-9214aad0b0e3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3f713b4e-3b17-497b-974c-9214aad0b0e3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3f713b4e-3b17-497b-974c-9214aad0b0e3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":180}],"source":["dataframe = customize_dataset(dataframe_raw, your_name)\n","dataframe.head()"]},{"cell_type":"markdown","metadata":{"id":"zn2qKrGX-yME"},"source":["Let us answer some basic questions about the dataset. \n","\n","\n","**Q1: How many rows does the dataset have?**"]},{"cell_type":"code","execution_count":181,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1649779229066,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"0gacRIEB-yME","outputId":"cd5e5952-0e99-44a5-bacb-df1d24afb0f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["1271\n"]}],"source":["num_rows = len(dataframe)\n","print(num_rows)"]},{"cell_type":"markdown","metadata":{"id":"H8yVKo12-yMF"},"source":["**Q2: How many columns doe the dataset have**"]},{"cell_type":"code","execution_count":182,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1649779230440,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"B0SSEiic-yMF","outputId":"45436db3-80bc-4eff-d426-ce9db57e7a3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["6\n"]}],"source":["num_cols = len(dataframe.columns)\n","print(num_cols)"]},{"cell_type":"markdown","metadata":{"id":"UCUxFfza-yMG"},"source":["**Q3: What are the column titles of the input variables?**"]},{"cell_type":"code","execution_count":183,"metadata":{"id":"qXV1E2ur-yMG","executionInfo":{"status":"ok","timestamp":1649779231173,"user_tz":-60,"elapsed":4,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["input_cols = list(dataframe.drop([\"charges\"], axis=1).columns)"]},{"cell_type":"markdown","metadata":{"id":"DqgHPdjX-yMG"},"source":["**Q4: Which of the input columns are non-numeric or categorial variables ?**\n","\n","Hint: `sex` is one of them. List the columns that are not numbers."]},{"cell_type":"code","execution_count":184,"metadata":{"id":"kVbcsYRs-yMH","executionInfo":{"status":"ok","timestamp":1649779232735,"user_tz":-60,"elapsed":4,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["categorical_cols = [\"sex\", \"smoker\"]"]},{"cell_type":"markdown","metadata":{"id":"BkhOnsKk-yMI"},"source":["**Q5: What are the column titles of output/target variable(s)?**"]},{"cell_type":"code","execution_count":185,"metadata":{"id":"6v9rfT1b-yMI","executionInfo":{"status":"ok","timestamp":1649779233370,"user_tz":-60,"elapsed":3,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["output_cols = [\"charges\"]"]},{"cell_type":"markdown","metadata":{"id":"df6IBFnA-yMK"},"source":["**Q: (Optional) What is the minimum, maximum and average value of the `charges` column? Can you show the distribution of values in a graph?**\n","Use this data visualization cheatsheet for referece: https://jovian.ai/aakashns/dataviz-cheatsheet"]},{"cell_type":"code","execution_count":186,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1649779234826,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"BG7lf9aa-yMK","outputId":"2bd95aa8-8aa9-4232-c1eb-1691b2e1bdcb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1234.06129, 70147.470811, 14567.360432224936)"]},"metadata":{},"execution_count":186},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# Write your answer here\n","\n","min_charge = dataframe[\"charges\"].min()\n","max_charge = dataframe[\"charges\"].max()\n","average_charge = dataframe[\"charges\"].mean()\n","# dataframe[\"charges\"].describe()[\"mean\"]\n","\n","dataframe[\"charges\"].hist(bins=10)\n","min_charge, max_charge, average_charge"]},{"cell_type":"markdown","metadata":{"id":"JUX-n6BR-yML"},"source":["Remember to commit your notebook to Jovian after every step, so that you don't lose your work."]},{"cell_type":"code","execution_count":187,"metadata":{"id":"1OadLxN_-yML","executionInfo":{"status":"ok","timestamp":1649779244020,"user_tz":-60,"elapsed":7158,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["!pip install jovian --upgrade -q"]},{"cell_type":"code","execution_count":188,"metadata":{"id":"xkLsJvFm-yML","executionInfo":{"status":"ok","timestamp":1649779244023,"user_tz":-60,"elapsed":15,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["import jovian"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T8rVPP6R-yMM","outputId":"dfdab11e-bfb6-4a87-aa7a-dae4a01f4e2f"},"outputs":[{"data":{"application/javascript":["window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[jovian] Attempting to save notebook..\u001b[0m\n","[jovian] Updating notebook \"aakashns/02-insurance-linear-regression\" on https://jovian.ai/\u001b[0m\n","[jovian] Uploading notebook..\u001b[0m\n","[jovian] Capturing environment..\u001b[0m\n","[jovian] Committed successfully! https://jovian.ai/aakashns/02-insurance-linear-regression\u001b[0m\n"]},{"data":{"text/plain":["'https://jovian.ai/aakashns/02-insurance-linear-regression'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["jovian.commit()"]},{"cell_type":"markdown","metadata":{"id":"D0fhJnwc-yMM"},"source":["## Step 2: Prepare the dataset for training\n","\n","We need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays."]},{"cell_type":"code","execution_count":189,"metadata":{"id":"OtwWy9zm-yMM","executionInfo":{"status":"ok","timestamp":1649779244024,"user_tz":-60,"elapsed":15,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["def dataframe_to_arrays(dataframe):\n","    # Make a copy of the original dataframe\n","    dataframe1 = dataframe.copy(deep=True)\n","    # Convert non-numeric categorical columns to numbers\n","    for col in categorical_cols:\n","        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n","    # Extract input & outupts as numpy arrays\n","    inputs_array = dataframe1[input_cols].to_numpy()\n","    targets_array = dataframe1[output_cols].to_numpy()\n","    return inputs_array, targets_array"]},{"cell_type":"markdown","metadata":{"id":"RMBzIMjz-yMN"},"source":["Read through the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) to understand how we're converting categorical variables into numbers."]},{"cell_type":"code","execution_count":190,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1649779244025,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"YhsBhfvu-yMN","outputId":"d3040d63-0241-43d5-f4d7-99d1edd354dd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[44.     ,  1.     , 29.7693 ,  2.     ,  0.     ],\n","        [64.     ,  0.     , 29.21155,  3.     ,  0.     ],\n","        [31.     ,  1.     , 28.9157 ,  0.     ,  1.     ],\n","        ...,\n","        [18.     ,  0.     , 39.0716 ,  0.     ,  0.     ],\n","        [54.     ,  1.     , 24.6962 ,  1.     ,  0.     ],\n","        [46.     ,  1.     , 25.8214 ,  1.     ,  0.     ]]),\n"," array([[ 8504.56981 ],\n","        [18101.278635],\n","        [21285.40579 ],\n","        ...,\n","        [ 2439.36132 ],\n","        [28068.824993],\n","        [ 8516.32078 ]]))"]},"metadata":{},"execution_count":190}],"source":["inputs_array, targets_array = dataframe_to_arrays(dataframe)\n","inputs_array, targets_array"]},{"cell_type":"markdown","metadata":{"id":"hi5oSsSm-yMN"},"source":["**Q6: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**"]},{"cell_type":"code","execution_count":191,"metadata":{"id":"bpezXMu_-yMN","executionInfo":{"status":"ok","timestamp":1649779244026,"user_tz":-60,"elapsed":14,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["inputs = torch.tensor(inputs_array, dtype=torch.float32)\n","targets = torch.tensor(targets_array, dtype=torch.float32)"]},{"cell_type":"code","execution_count":192,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57,"status":"ok","timestamp":1649779244739,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"LbhcwhLW-yMO","outputId":"88f35acb-dd9d-4717-b595-2f3f70c90668"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.float32, torch.float32)"]},"metadata":{},"execution_count":192}],"source":["inputs.dtype, targets.dtype"]},{"cell_type":"markdown","metadata":{"id":"uamV6eQy-yMO"},"source":["Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`."]},{"cell_type":"code","execution_count":193,"metadata":{"id":"8kbqQHWC-yMO","executionInfo":{"status":"ok","timestamp":1649779245506,"user_tz":-60,"elapsed":7,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["dataset = TensorDataset(inputs, targets)"]},{"cell_type":"markdown","metadata":{"id":"JUy8XX6l-yMP"},"source":["**Q7: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets.**"]},{"cell_type":"code","execution_count":194,"metadata":{"id":"hB8zv8GA-yMP","executionInfo":{"status":"ok","timestamp":1649779246282,"user_tz":-60,"elapsed":5,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["val_percent = 0.1 # between 0.1 and 0.2\n","val_size = int(num_rows * val_percent)\n","train_size = num_rows - val_size\n","\n","\n","train_ds, val_ds = random_split(dataset, [train_size, val_size]) # Use the random_split function to split dataset into 2 parts of the desired length"]},{"cell_type":"markdown","metadata":{"id":"e3YCTvrD-yMP"},"source":["Finally, we can create data loaders for training & validation.\n","\n","**Q8: Pick a batch size for the data loader.**"]},{"cell_type":"code","execution_count":195,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1649779246994,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"PU78c952-yMQ"},"outputs":[],"source":["batch_size = 32"]},{"cell_type":"code","execution_count":196,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1649779247795,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"xlPDqIuV-yMQ"},"outputs":[],"source":["train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n","val_loader = DataLoader(val_ds, batch_size)"]},{"cell_type":"markdown","metadata":{"id":"9_0J21YG-yMQ"},"source":["Let's look at a batch of data to verify everything is working fine so far."]},{"cell_type":"code","execution_count":197,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1649779248575,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"ePijWyvT-yMQ","outputId":"29d85aa7-a545-4028-e835-a40d8265f27c"},"outputs":[{"output_type":"stream","name":"stdout","text":["inputs: tensor([[26.0000,  1.0000, 20.1760,  0.0000,  0.0000],\n","        [60.0000,  0.0000, 31.4765,  0.0000,  1.0000],\n","        [50.0000,  1.0000, 35.1140,  0.0000,  0.0000],\n","        [22.0000,  0.0000, 26.2870,  0.0000,  0.0000],\n","        [43.0000,  0.0000, 29.7645,  2.0000,  0.0000],\n","        [40.0000,  0.0000, 22.6689,  3.0000,  0.0000],\n","        [34.0000,  1.0000, 20.7337,  0.0000,  0.0000],\n","        [36.0000,  0.0000, 19.2593,  0.0000,  0.0000],\n","        [44.0000,  1.0000, 29.2940,  2.0000,  1.0000],\n","        [37.0000,  0.0000, 37.2383,  0.0000,  1.0000],\n","        [19.0000,  0.0000, 30.8703,  1.0000,  0.0000],\n","        [32.0000,  0.0000, 28.0621,  0.0000,  0.0000],\n","        [41.0000,  1.0000, 31.2340,  2.0000,  0.0000],\n","        [18.0000,  0.0000, 30.9624,  0.0000,  0.0000],\n","        [61.0000,  1.0000, 31.3310,  2.0000,  0.0000],\n","        [25.0000,  1.0000, 25.0648,  1.0000,  0.0000],\n","        [21.0000,  0.0000, 33.5620,  0.0000,  0.0000],\n","        [35.0000,  0.0000, 34.7406,  1.0000,  0.0000],\n","        [56.0000,  0.0000, 40.6527,  0.0000,  0.0000],\n","        [33.0000,  1.0000, 23.8668,  2.0000,  0.0000],\n","        [27.0000,  1.0000, 40.8661,  0.0000,  1.0000],\n","        [60.0000,  0.0000, 25.0648,  0.0000,  0.0000],\n","        [21.0000,  1.0000, 30.0894,  0.0000,  0.0000],\n","        [33.0000,  0.0000, 41.6518,  3.0000,  0.0000],\n","        [30.0000,  1.0000, 34.4641,  0.0000,  1.0000],\n","        [35.0000,  1.0000, 33.2904,  3.0000,  0.0000],\n","        [27.0000,  0.0000, 30.3174,  1.0000,  0.0000],\n","        [39.0000,  0.0000, 25.5256,  2.0000,  0.0000],\n","        [54.0000,  1.0000, 20.3797,  2.0000,  0.0000],\n","        [29.0000,  1.0000, 31.1467,  2.0000,  0.0000],\n","        [32.0000,  1.0000, 29.8760,  3.0000,  0.0000],\n","        [47.0000,  0.0000, 32.3447,  0.0000,  0.0000]])\n","targets: tensor([[ 2532.5300],\n","        [49509.8516],\n","        [ 9303.5996],\n","        [ 2369.7971],\n","        [ 9141.9229],\n","        [ 9077.5127],\n","        [ 4950.3730],\n","        [ 6003.8511],\n","        [42898.4023],\n","        [44460.9219],\n","        [ 2991.2078],\n","        [ 4370.2173],\n","        [ 7563.5571],\n","        [ 2426.5789],\n","        [15531.5820],\n","        [ 3640.7720],\n","        [ 2222.1946],\n","        [ 6193.5034],\n","        [12202.9854],\n","        [ 5783.2588],\n","        [43572.9336],\n","        [31815.4512],\n","        [18245.1484],\n","        [ 6997.0928],\n","        [40645.2812],\n","        [ 6527.8179],\n","        [ 4351.6787],\n","        [ 7921.8711],\n","        [12115.0830],\n","        [ 4877.3076],\n","        [ 5778.8765],\n","        [22966.6621]])\n"]}],"source":["for xb, yb in train_loader:\n","    print(\"inputs:\", xb)\n","    print(\"targets:\", yb)\n","    break"]},{"cell_type":"markdown","metadata":{"id":"UjQcnC08-yMR"},"source":["Let's save our work by committing to Jovian."]},{"cell_type":"code","execution_count":199,"metadata":{"id":"zQKzMuU1-yMR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649779251714,"user_tz":-60,"elapsed":12,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}},"outputId":"a9289fd7-d222-45b2-9829-d0e6d6b7ad04"},"outputs":[{"output_type":"stream","name":"stdout","text":["[jovian] Detected Colab notebook...\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[31m[jovian] Error: jovian.commit doesn't work on Colab unless the notebook was created and executed from Jovian.\n","Make sure to run the first code cell at the top after executing from Jovian.\n","Alternatively, you can download this notebook and upload it manually to Jovian.\n","Learn more: https://jovian.ai/docs/user-guide/run.html#run-on-colab\u001b[0m\n"]}],"source":["jovian.commit(project=project_name, environment=None)"]},{"cell_type":"markdown","metadata":{"id":"08OpnGBm-yMR"},"source":["## Step 3: Create a Linear Regression Model\n","\n","Our model itself is a fairly straightforward linear regression (we'll build more complex models in the next assignment). \n"]},{"cell_type":"code","execution_count":200,"metadata":{"executionInfo":{"elapsed":731,"status":"ok","timestamp":1649779257123,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"HD8bvrZ--yMR"},"outputs":[],"source":["input_size = len(input_cols)\n","output_size = len(output_cols)"]},{"cell_type":"markdown","metadata":{"id":"T_Jo7tJV-yMR"},"source":["**Q9: Complete the class definition below by filling out the constructor (`__init__`), `forward`, `training_step` and `validation_step` methods.**\n","\n","Hint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See https://pytorch.org/docs/stable/nn.functional.html#loss-functions"]},{"cell_type":"code","execution_count":201,"metadata":{"id":"rQxQX2IZ-yMS","executionInfo":{"status":"ok","timestamp":1649779257754,"user_tz":-60,"elapsed":3,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["class InsuranceModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.linear = nn.Linear(input_size, output_size)                  # fill this (hint: use input_size & output_size defined above)\n","        \n","    def forward(self, xb):\n","        out = self.linear(xb)                          # fill this\n","        return out\n","    \n","    def training_step(self, batch):\n","        inputs, targets = batch \n","        # Generate predictions\n","        out = self(inputs)          \n","        # Calcuate loss\n","        loss = F.mse_loss(out, targets)                          # fill this\n","        return loss\n","    \n","    def validation_step(self, batch):\n","        inputs, targets = batch\n","        # Generate predictions\n","        out = self(inputs)\n","        # Calculate loss\n","        loss = F.mse_loss(out, targets)                            # fill this    \n","        return {'val_loss': loss.detach()}\n","        \n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        return {'val_loss': epoch_loss.item()}\n","    \n","    def epoch_end(self, epoch, result, num_epochs):\n","        # Print result every 20th epoch\n","        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n","            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"]},{"cell_type":"markdown","metadata":{"id":"VPrpZ3Lq-yMS"},"source":["Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`."]},{"cell_type":"code","execution_count":202,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1649779259201,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"L63-YzQA-yMS"},"outputs":[],"source":["model = InsuranceModel()"]},{"cell_type":"markdown","metadata":{"id":"1szzzjjm-yMT"},"source":["Let's check out the weights and biases of the model using `model.parameters`."]},{"cell_type":"code","execution_count":203,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1649779262097,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"ebpwJo2R-yMT","outputId":"e8e5edff-b544-4eac-ae01-130c5b188d72"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Parameter containing:\n"," tensor([[ 0.0720, -0.1522,  0.2316,  0.0300,  0.4470]], requires_grad=True),\n"," Parameter containing:\n"," tensor([0.2163], requires_grad=True)]"]},"metadata":{},"execution_count":203}],"source":["list(model.parameters())"]},{"cell_type":"markdown","metadata":{"id":"31g8-OP1-yMT"},"source":["One final commit before we train the model."]},{"cell_type":"code","execution_count":204,"metadata":{"id":"hYljV9pS-yMT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649779263666,"user_tz":-60,"elapsed":743,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}},"outputId":"be20e733-3aa2-4098-b278-bccdfcf18fa7"},"outputs":[{"output_type":"stream","name":"stdout","text":["[jovian] Detected Colab notebook...\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[31m[jovian] Error: jovian.commit doesn't work on Colab unless the notebook was created and executed from Jovian.\n","Make sure to run the first code cell at the top after executing from Jovian.\n","Alternatively, you can download this notebook and upload it manually to Jovian.\n","Learn more: https://jovian.ai/docs/user-guide/run.html#run-on-colab\u001b[0m\n"]}],"source":["jovian.commit(project=project_name, environment=None)"]},{"cell_type":"markdown","metadata":{"id":"TNqV27zb-yMU"},"source":["## Step 4: Train the model to fit the data\n","\n","To train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem."]},{"cell_type":"code","execution_count":205,"metadata":{"id":"OUTkdB3x-yMU","executionInfo":{"status":"ok","timestamp":1649779264297,"user_tz":-60,"elapsed":8,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}}},"outputs":[],"source":["def evaluate(model, val_loader):\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    return model.validation_epoch_end(outputs)\n","\n","def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n","    history = []\n","    optimizer = opt_func(model.parameters(), lr)\n","    for epoch in range(epochs):\n","        # Training Phase \n","        for batch in train_loader:\n","            loss = model.training_step(batch)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","        # Validation phase\n","        result = evaluate(model, val_loader)\n","        model.epoch_end(epoch, result, epochs)\n","        history.append(result)\n","    return history"]},{"cell_type":"markdown","metadata":{"id":"OJwXt2aH-yMV"},"source":["**Q10: Use the `evaluate` function to calculate the loss on the validation set before training.**"]},{"cell_type":"code","execution_count":206,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1649779266332,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"iDDzLOqC-yMV","outputId":"fc0a3562-53b0-4ee3-92a6-a16369c91ffb"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'val_loss': 372852736.0}\n"]}],"source":["result = evaluate(model, val_loader) # Use the the evaluate function\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"0ZQvcbQu-yMW"},"source":["\n","We are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible."]},{"cell_type":"markdown","metadata":{"id":"viY-kF_J-yMW"},"source":["**Q11: Train the model 4-5 times with different learning rates & for different number of epochs.**\n","\n","Hint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works."]},{"cell_type":"code","execution_count":207,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1649779269317,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"4nUgIclPIrn0"},"outputs":[],"source":["model = InsuranceModel()"]},{"cell_type":"code","execution_count":208,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":105460,"status":"ok","timestamp":1649779404920,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"t7vY_Sye-yMW","outputId":"1d5f8f09-1c3a-4210-923b-c2afcfbba920"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [20], val_loss: 139923920.0000\n","Epoch [40], val_loss: 135368800.0000\n","Epoch [60], val_loss: 130079472.0000\n","Epoch [80], val_loss: 132007376.0000\n","Epoch [100], val_loss: 121160896.0000\n","Epoch [120], val_loss: 117058400.0000\n","Epoch [140], val_loss: 113932256.0000\n","Epoch [160], val_loss: 112133072.0000\n","Epoch [180], val_loss: 109439752.0000\n","Epoch [200], val_loss: 102860672.0000\n","Epoch [220], val_loss: 104915928.0000\n","Epoch [240], val_loss: 96465664.0000\n","Epoch [260], val_loss: 93638176.0000\n","Epoch [280], val_loss: 92773248.0000\n","Epoch [300], val_loss: 88462040.0000\n","Epoch [320], val_loss: 94042768.0000\n","Epoch [340], val_loss: 93356280.0000\n","Epoch [360], val_loss: 81340608.0000\n","Epoch [380], val_loss: 84575744.0000\n","Epoch [400], val_loss: 80625528.0000\n","Epoch [420], val_loss: 78731568.0000\n","Epoch [440], val_loss: 80247696.0000\n","Epoch [460], val_loss: 71467952.0000\n","Epoch [480], val_loss: 92859440.0000\n","Epoch [500], val_loss: 69027832.0000\n","Epoch [520], val_loss: 66807224.0000\n","Epoch [540], val_loss: 65180496.0000\n","Epoch [560], val_loss: 64508112.0000\n","Epoch [580], val_loss: 62514136.0000\n","Epoch [600], val_loss: 63288800.0000\n","Epoch [620], val_loss: 62024496.0000\n","Epoch [640], val_loss: 62665020.0000\n","Epoch [660], val_loss: 62125964.0000\n","Epoch [680], val_loss: 56905120.0000\n","Epoch [700], val_loss: 56619632.0000\n","Epoch [720], val_loss: 55450216.0000\n","Epoch [740], val_loss: 55655608.0000\n","Epoch [760], val_loss: 56853356.0000\n","Epoch [780], val_loss: 52259544.0000\n","Epoch [800], val_loss: 55215824.0000\n","Epoch [820], val_loss: 50774100.0000\n","Epoch [840], val_loss: 49999348.0000\n","Epoch [860], val_loss: 55139240.0000\n","Epoch [880], val_loss: 48683144.0000\n","Epoch [900], val_loss: 48104964.0000\n","Epoch [920], val_loss: 51205496.0000\n","Epoch [940], val_loss: 49126008.0000\n","Epoch [960], val_loss: 46409952.0000\n","Epoch [980], val_loss: 47067940.0000\n","Epoch [1000], val_loss: 46845008.0000\n","Epoch [1020], val_loss: 46483344.0000\n","Epoch [1040], val_loss: 52204856.0000\n","Epoch [1060], val_loss: 46578836.0000\n","Epoch [1080], val_loss: 44958772.0000\n","Epoch [1100], val_loss: 44280112.0000\n","Epoch [1120], val_loss: 43116032.0000\n","Epoch [1140], val_loss: 44369564.0000\n","Epoch [1160], val_loss: 42204216.0000\n","Epoch [1180], val_loss: 43200032.0000\n","Epoch [1200], val_loss: 42371160.0000\n","Epoch [1220], val_loss: 44511284.0000\n","Epoch [1240], val_loss: 42552872.0000\n","Epoch [1260], val_loss: 43932056.0000\n","Epoch [1280], val_loss: 41560076.0000\n","Epoch [1300], val_loss: 40524960.0000\n","Epoch [1320], val_loss: 45866440.0000\n","Epoch [1340], val_loss: 42666684.0000\n","Epoch [1360], val_loss: 39917144.0000\n","Epoch [1380], val_loss: 39637784.0000\n","Epoch [1400], val_loss: 39908700.0000\n","Epoch [1420], val_loss: 39004224.0000\n","Epoch [1440], val_loss: 40515096.0000\n","Epoch [1460], val_loss: 38743872.0000\n","Epoch [1480], val_loss: 39295908.0000\n","Epoch [1500], val_loss: 38395920.0000\n","Epoch [1520], val_loss: 41368844.0000\n","Epoch [1540], val_loss: 42585104.0000\n","Epoch [1560], val_loss: 42148012.0000\n","Epoch [1580], val_loss: 38237008.0000\n","Epoch [1600], val_loss: 39544816.0000\n","Epoch [1620], val_loss: 38218224.0000\n","Epoch [1640], val_loss: 41038664.0000\n","Epoch [1660], val_loss: 37610544.0000\n","Epoch [1680], val_loss: 41427268.0000\n","Epoch [1700], val_loss: 37577552.0000\n","Epoch [1720], val_loss: 38655504.0000\n","Epoch [1740], val_loss: 37218520.0000\n","Epoch [1760], val_loss: 43879264.0000\n","Epoch [1780], val_loss: 36767288.0000\n","Epoch [1800], val_loss: 37422052.0000\n","Epoch [1820], val_loss: 37612560.0000\n","Epoch [1840], val_loss: 38175632.0000\n","Epoch [1860], val_loss: 37105148.0000\n","Epoch [1880], val_loss: 36379640.0000\n","Epoch [1900], val_loss: 38529940.0000\n","Epoch [1920], val_loss: 38685544.0000\n","Epoch [1940], val_loss: 36264136.0000\n","Epoch [1960], val_loss: 36165368.0000\n","Epoch [1980], val_loss: 36790824.0000\n","Epoch [2000], val_loss: 36105524.0000\n","Epoch [2020], val_loss: 37312296.0000\n","Epoch [2040], val_loss: 36111080.0000\n","Epoch [2060], val_loss: 37352120.0000\n","Epoch [2080], val_loss: 36853792.0000\n","Epoch [2100], val_loss: 38575092.0000\n","Epoch [2120], val_loss: 36176972.0000\n","Epoch [2140], val_loss: 36040220.0000\n","Epoch [2160], val_loss: 35789932.0000\n","Epoch [2180], val_loss: 36978488.0000\n","Epoch [2200], val_loss: 37801872.0000\n","Epoch [2220], val_loss: 36995276.0000\n","Epoch [2240], val_loss: 35525632.0000\n","Epoch [2260], val_loss: 35346492.0000\n","Epoch [2280], val_loss: 39534836.0000\n","Epoch [2300], val_loss: 35506804.0000\n","Epoch [2320], val_loss: 35229744.0000\n","Epoch [2340], val_loss: 36611944.0000\n","Epoch [2360], val_loss: 37805700.0000\n","Epoch [2380], val_loss: 36379336.0000\n","Epoch [2400], val_loss: 36323160.0000\n","Epoch [2420], val_loss: 37898816.0000\n","Epoch [2440], val_loss: 37666496.0000\n","Epoch [2460], val_loss: 35577460.0000\n","Epoch [2480], val_loss: 36386052.0000\n","Epoch [2500], val_loss: 35603632.0000\n","Epoch [2520], val_loss: 36338304.0000\n","Epoch [2540], val_loss: 37974592.0000\n","Epoch [2560], val_loss: 35156768.0000\n","Epoch [2580], val_loss: 45880264.0000\n","Epoch [2600], val_loss: 39276980.0000\n","Epoch [2620], val_loss: 36009500.0000\n","Epoch [2640], val_loss: 35157644.0000\n","Epoch [2660], val_loss: 38156632.0000\n","Epoch [2680], val_loss: 34789456.0000\n","Epoch [2700], val_loss: 34764308.0000\n","Epoch [2720], val_loss: 37787100.0000\n","Epoch [2740], val_loss: 34757588.0000\n","Epoch [2760], val_loss: 34659736.0000\n","Epoch [2780], val_loss: 35493220.0000\n","Epoch [2800], val_loss: 37189524.0000\n","Epoch [2820], val_loss: 38594728.0000\n","Epoch [2840], val_loss: 37229400.0000\n","Epoch [2860], val_loss: 37301872.0000\n","Epoch [2880], val_loss: 38193004.0000\n","Epoch [2900], val_loss: 37096984.0000\n","Epoch [2920], val_loss: 39376592.0000\n","Epoch [2940], val_loss: 38279640.0000\n","Epoch [2960], val_loss: 34480816.0000\n","Epoch [2980], val_loss: 38368952.0000\n","Epoch [3000], val_loss: 36469976.0000\n","Epoch [3020], val_loss: 37698964.0000\n","Epoch [3040], val_loss: 35203276.0000\n","Epoch [3060], val_loss: 35264828.0000\n","Epoch [3080], val_loss: 35007360.0000\n","Epoch [3100], val_loss: 37973252.0000\n","Epoch [3120], val_loss: 37519256.0000\n","Epoch [3140], val_loss: 36880360.0000\n","Epoch [3160], val_loss: 37924736.0000\n","Epoch [3180], val_loss: 38675848.0000\n","Epoch [3200], val_loss: 34265264.0000\n","Epoch [3220], val_loss: 36215932.0000\n","Epoch [3240], val_loss: 35631208.0000\n","Epoch [3260], val_loss: 34271560.0000\n","Epoch [3280], val_loss: 34266116.0000\n","Epoch [3300], val_loss: 47911588.0000\n","Epoch [3320], val_loss: 35790616.0000\n","Epoch [3340], val_loss: 34904704.0000\n","Epoch [3360], val_loss: 39015136.0000\n","Epoch [3380], val_loss: 37094164.0000\n","Epoch [3400], val_loss: 34332556.0000\n","Epoch [3420], val_loss: 38293876.0000\n","Epoch [3440], val_loss: 34023800.0000\n","Epoch [3460], val_loss: 35539684.0000\n","Epoch [3480], val_loss: 34052664.0000\n","Epoch [3500], val_loss: 35085440.0000\n","Epoch [3520], val_loss: 34269568.0000\n","Epoch [3540], val_loss: 35205336.0000\n","Epoch [3560], val_loss: 33992192.0000\n","Epoch [3580], val_loss: 35026704.0000\n","Epoch [3600], val_loss: 34726576.0000\n","Epoch [3620], val_loss: 34221392.0000\n","Epoch [3640], val_loss: 39353472.0000\n","Epoch [3660], val_loss: 36781580.0000\n","Epoch [3680], val_loss: 34097500.0000\n","Epoch [3700], val_loss: 36837632.0000\n","Epoch [3720], val_loss: 36235212.0000\n","Epoch [3740], val_loss: 34719984.0000\n","Epoch [3760], val_loss: 42006188.0000\n","Epoch [3780], val_loss: 39208520.0000\n","Epoch [3800], val_loss: 34681740.0000\n","Epoch [3820], val_loss: 35632752.0000\n","Epoch [3840], val_loss: 33782072.0000\n","Epoch [3860], val_loss: 36853200.0000\n","Epoch [3880], val_loss: 34644376.0000\n","Epoch [3900], val_loss: 35282736.0000\n","Epoch [3920], val_loss: 35649488.0000\n","Epoch [3940], val_loss: 35424100.0000\n","Epoch [3960], val_loss: 35210100.0000\n","Epoch [3980], val_loss: 34007064.0000\n","Epoch [4000], val_loss: 33663048.0000\n","Epoch [4020], val_loss: 34550360.0000\n","Epoch [4040], val_loss: 33953524.0000\n","Epoch [4060], val_loss: 34324056.0000\n","Epoch [4080], val_loss: 33590060.0000\n","Epoch [4100], val_loss: 35011988.0000\n","Epoch [4120], val_loss: 37937168.0000\n","Epoch [4140], val_loss: 33641180.0000\n","Epoch [4160], val_loss: 35990824.0000\n","Epoch [4180], val_loss: 34338928.0000\n","Epoch [4200], val_loss: 35114016.0000\n","Epoch [4220], val_loss: 34044768.0000\n","Epoch [4240], val_loss: 33947832.0000\n","Epoch [4260], val_loss: 35254956.0000\n","Epoch [4280], val_loss: 36153508.0000\n","Epoch [4300], val_loss: 33463668.0000\n","Epoch [4320], val_loss: 33661520.0000\n","Epoch [4340], val_loss: 40521936.0000\n","Epoch [4360], val_loss: 36778656.0000\n","Epoch [4380], val_loss: 33785344.0000\n","Epoch [4400], val_loss: 38501136.0000\n","Epoch [4420], val_loss: 34360556.0000\n","Epoch [4440], val_loss: 34848528.0000\n","Epoch [4460], val_loss: 37572700.0000\n","Epoch [4480], val_loss: 33490196.0000\n","Epoch [4500], val_loss: 38332412.0000\n","Epoch [4520], val_loss: 34419100.0000\n","Epoch [4540], val_loss: 34482720.0000\n","Epoch [4560], val_loss: 33355384.0000\n","Epoch [4580], val_loss: 35297448.0000\n","Epoch [4600], val_loss: 38897120.0000\n","Epoch [4620], val_loss: 35046624.0000\n","Epoch [4640], val_loss: 33481390.0000\n","Epoch [4660], val_loss: 34235268.0000\n","Epoch [4680], val_loss: 34664032.0000\n","Epoch [4700], val_loss: 35636220.0000\n","Epoch [4720], val_loss: 33895788.0000\n","Epoch [4740], val_loss: 35319904.0000\n","Epoch [4760], val_loss: 33520808.0000\n","Epoch [4780], val_loss: 33715344.0000\n","Epoch [4800], val_loss: 33781496.0000\n","Epoch [4820], val_loss: 33478226.0000\n","Epoch [4840], val_loss: 34734060.0000\n","Epoch [4860], val_loss: 33684184.0000\n","Epoch [4880], val_loss: 34443468.0000\n","Epoch [4900], val_loss: 34203628.0000\n","Epoch [4920], val_loss: 36775496.0000\n","Epoch [4940], val_loss: 33807704.0000\n","Epoch [4960], val_loss: 34993592.0000\n","Epoch [4980], val_loss: 34361452.0000\n","Epoch [5000], val_loss: 33102700.0000\n"]}],"source":["epochs = 5000\n","lr = 1e-4\n","history1 = fit(epochs, lr, model, train_loader, val_loader)"]},{"cell_type":"code","execution_count":209,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104573,"status":"ok","timestamp":1649779509462,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"y4uEsD5i-yMW","outputId":"7792165b-a546-46a0-fe67-4bc9064e76c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [20], val_loss: 34876308.0000\n","Epoch [40], val_loss: 34170464.0000\n","Epoch [60], val_loss: 35114488.0000\n","Epoch [80], val_loss: 34140884.0000\n","Epoch [100], val_loss: 33933916.0000\n","Epoch [120], val_loss: 34887984.0000\n","Epoch [140], val_loss: 34246912.0000\n","Epoch [160], val_loss: 33355080.0000\n","Epoch [180], val_loss: 34972492.0000\n","Epoch [200], val_loss: 34157876.0000\n","Epoch [220], val_loss: 34352384.0000\n","Epoch [240], val_loss: 33738512.0000\n","Epoch [260], val_loss: 36844608.0000\n","Epoch [280], val_loss: 34236936.0000\n","Epoch [300], val_loss: 34014916.0000\n","Epoch [320], val_loss: 34278056.0000\n","Epoch [340], val_loss: 33383600.0000\n","Epoch [360], val_loss: 34441844.0000\n","Epoch [380], val_loss: 34209192.0000\n","Epoch [400], val_loss: 33634744.0000\n","Epoch [420], val_loss: 33813592.0000\n","Epoch [440], val_loss: 33131732.0000\n","Epoch [460], val_loss: 33593952.0000\n","Epoch [480], val_loss: 33752056.0000\n","Epoch [500], val_loss: 34422088.0000\n","Epoch [520], val_loss: 33364224.0000\n","Epoch [540], val_loss: 32973438.0000\n","Epoch [560], val_loss: 33382112.0000\n","Epoch [580], val_loss: 38381104.0000\n","Epoch [600], val_loss: 33590268.0000\n","Epoch [620], val_loss: 33451672.0000\n","Epoch [640], val_loss: 33789136.0000\n","Epoch [660], val_loss: 33662920.0000\n","Epoch [680], val_loss: 33344988.0000\n","Epoch [700], val_loss: 33278882.0000\n","Epoch [720], val_loss: 33259438.0000\n","Epoch [740], val_loss: 33079718.0000\n","Epoch [760], val_loss: 34146120.0000\n","Epoch [780], val_loss: 34131376.0000\n","Epoch [800], val_loss: 34233280.0000\n","Epoch [820], val_loss: 33615872.0000\n","Epoch [840], val_loss: 35262480.0000\n","Epoch [860], val_loss: 34055240.0000\n","Epoch [880], val_loss: 33431464.0000\n","Epoch [900], val_loss: 33516824.0000\n","Epoch [920], val_loss: 33230296.0000\n","Epoch [940], val_loss: 38706864.0000\n","Epoch [960], val_loss: 34898420.0000\n","Epoch [980], val_loss: 34444680.0000\n","Epoch [1000], val_loss: 35340864.0000\n","Epoch [1020], val_loss: 35263256.0000\n","Epoch [1040], val_loss: 33354108.0000\n","Epoch [1060], val_loss: 34615448.0000\n","Epoch [1080], val_loss: 33792048.0000\n","Epoch [1100], val_loss: 34380520.0000\n","Epoch [1120], val_loss: 33942120.0000\n","Epoch [1140], val_loss: 33218012.0000\n","Epoch [1160], val_loss: 36374032.0000\n","Epoch [1180], val_loss: 33659216.0000\n","Epoch [1200], val_loss: 33990940.0000\n","Epoch [1220], val_loss: 33390822.0000\n","Epoch [1240], val_loss: 33089364.0000\n","Epoch [1260], val_loss: 33475956.0000\n","Epoch [1280], val_loss: 33389656.0000\n","Epoch [1300], val_loss: 33872020.0000\n","Epoch [1320], val_loss: 32855252.0000\n","Epoch [1340], val_loss: 33051616.0000\n","Epoch [1360], val_loss: 36118452.0000\n","Epoch [1380], val_loss: 34321512.0000\n","Epoch [1400], val_loss: 33259506.0000\n","Epoch [1420], val_loss: 33043440.0000\n","Epoch [1440], val_loss: 33607720.0000\n","Epoch [1460], val_loss: 35096648.0000\n","Epoch [1480], val_loss: 39124512.0000\n","Epoch [1500], val_loss: 33820488.0000\n","Epoch [1520], val_loss: 33180500.0000\n","Epoch [1540], val_loss: 33018238.0000\n","Epoch [1560], val_loss: 33656000.0000\n","Epoch [1580], val_loss: 33211476.0000\n","Epoch [1600], val_loss: 34644592.0000\n","Epoch [1620], val_loss: 32843034.0000\n","Epoch [1640], val_loss: 36537952.0000\n","Epoch [1660], val_loss: 33200244.0000\n","Epoch [1680], val_loss: 33905560.0000\n","Epoch [1700], val_loss: 33943420.0000\n","Epoch [1720], val_loss: 34320264.0000\n","Epoch [1740], val_loss: 33772948.0000\n","Epoch [1760], val_loss: 32856780.0000\n","Epoch [1780], val_loss: 33149912.0000\n","Epoch [1800], val_loss: 33832356.0000\n","Epoch [1820], val_loss: 34350564.0000\n","Epoch [1840], val_loss: 33299736.0000\n","Epoch [1860], val_loss: 32745812.0000\n","Epoch [1880], val_loss: 32932580.0000\n","Epoch [1900], val_loss: 32941718.0000\n","Epoch [1920], val_loss: 32915376.0000\n","Epoch [1940], val_loss: 33421700.0000\n","Epoch [1960], val_loss: 34326428.0000\n","Epoch [1980], val_loss: 33602904.0000\n","Epoch [2000], val_loss: 33870640.0000\n","Epoch [2020], val_loss: 33446544.0000\n","Epoch [2040], val_loss: 34417248.0000\n","Epoch [2060], val_loss: 32775268.0000\n","Epoch [2080], val_loss: 35801200.0000\n","Epoch [2100], val_loss: 32839134.0000\n","Epoch [2120], val_loss: 36720536.0000\n","Epoch [2140], val_loss: 37074312.0000\n","Epoch [2160], val_loss: 33719708.0000\n","Epoch [2180], val_loss: 33115980.0000\n","Epoch [2200], val_loss: 34514776.0000\n","Epoch [2220], val_loss: 34480224.0000\n","Epoch [2240], val_loss: 34992384.0000\n","Epoch [2260], val_loss: 33812492.0000\n","Epoch [2280], val_loss: 35448488.0000\n","Epoch [2300], val_loss: 33597608.0000\n","Epoch [2320], val_loss: 33561644.0000\n","Epoch [2340], val_loss: 33916012.0000\n","Epoch [2360], val_loss: 34510580.0000\n","Epoch [2380], val_loss: 34454328.0000\n","Epoch [2400], val_loss: 32837190.0000\n","Epoch [2420], val_loss: 34385964.0000\n","Epoch [2440], val_loss: 35259232.0000\n","Epoch [2460], val_loss: 33475680.0000\n","Epoch [2480], val_loss: 33901424.0000\n","Epoch [2500], val_loss: 34474508.0000\n","Epoch [2520], val_loss: 33223566.0000\n","Epoch [2540], val_loss: 32752960.0000\n","Epoch [2560], val_loss: 35108784.0000\n","Epoch [2580], val_loss: 33324460.0000\n","Epoch [2600], val_loss: 32723864.0000\n","Epoch [2620], val_loss: 33749836.0000\n","Epoch [2640], val_loss: 33653552.0000\n","Epoch [2660], val_loss: 34181432.0000\n","Epoch [2680], val_loss: 33209752.0000\n","Epoch [2700], val_loss: 33932884.0000\n","Epoch [2720], val_loss: 34723224.0000\n","Epoch [2740], val_loss: 34693372.0000\n","Epoch [2760], val_loss: 33650220.0000\n","Epoch [2780], val_loss: 35158280.0000\n","Epoch [2800], val_loss: 33331480.0000\n","Epoch [2820], val_loss: 33608388.0000\n","Epoch [2840], val_loss: 34194968.0000\n","Epoch [2860], val_loss: 32968892.0000\n","Epoch [2880], val_loss: 33368580.0000\n","Epoch [2900], val_loss: 33597480.0000\n","Epoch [2920], val_loss: 34226800.0000\n","Epoch [2940], val_loss: 32637920.0000\n","Epoch [2960], val_loss: 32808900.0000\n","Epoch [2980], val_loss: 33230640.0000\n","Epoch [3000], val_loss: 35259572.0000\n","Epoch [3020], val_loss: 33373576.0000\n","Epoch [3040], val_loss: 33722744.0000\n","Epoch [3060], val_loss: 35358144.0000\n","Epoch [3080], val_loss: 32538942.0000\n","Epoch [3100], val_loss: 33915824.0000\n","Epoch [3120], val_loss: 32683340.0000\n","Epoch [3140], val_loss: 33786780.0000\n","Epoch [3160], val_loss: 32939286.0000\n","Epoch [3180], val_loss: 32869494.0000\n","Epoch [3200], val_loss: 34963116.0000\n","Epoch [3220], val_loss: 34495972.0000\n","Epoch [3240], val_loss: 35575168.0000\n","Epoch [3260], val_loss: 33570160.0000\n","Epoch [3280], val_loss: 34058944.0000\n","Epoch [3300], val_loss: 35203468.0000\n","Epoch [3320], val_loss: 34070308.0000\n","Epoch [3340], val_loss: 33268424.0000\n","Epoch [3360], val_loss: 32492268.0000\n","Epoch [3380], val_loss: 35264804.0000\n","Epoch [3400], val_loss: 34789148.0000\n","Epoch [3420], val_loss: 32776732.0000\n","Epoch [3440], val_loss: 33208848.0000\n","Epoch [3460], val_loss: 33267630.0000\n","Epoch [3480], val_loss: 33511186.0000\n","Epoch [3500], val_loss: 32625616.0000\n","Epoch [3520], val_loss: 33273774.0000\n","Epoch [3540], val_loss: 32771988.0000\n","Epoch [3560], val_loss: 33032434.0000\n","Epoch [3580], val_loss: 33452308.0000\n","Epoch [3600], val_loss: 32607116.0000\n","Epoch [3620], val_loss: 33703344.0000\n","Epoch [3640], val_loss: 34789280.0000\n","Epoch [3660], val_loss: 33670320.0000\n","Epoch [3680], val_loss: 33462326.0000\n","Epoch [3700], val_loss: 35964296.0000\n","Epoch [3720], val_loss: 32857768.0000\n","Epoch [3740], val_loss: 34929624.0000\n","Epoch [3760], val_loss: 33165732.0000\n","Epoch [3780], val_loss: 36365800.0000\n","Epoch [3800], val_loss: 32949944.0000\n","Epoch [3820], val_loss: 33405000.0000\n","Epoch [3840], val_loss: 32448890.0000\n","Epoch [3860], val_loss: 33064120.0000\n","Epoch [3880], val_loss: 32849038.0000\n","Epoch [3900], val_loss: 32611034.0000\n","Epoch [3920], val_loss: 33960880.0000\n","Epoch [3940], val_loss: 32730980.0000\n","Epoch [3960], val_loss: 32889348.0000\n","Epoch [3980], val_loss: 33061472.0000\n","Epoch [4000], val_loss: 33486552.0000\n","Epoch [4020], val_loss: 32441252.0000\n","Epoch [4040], val_loss: 34115104.0000\n","Epoch [4060], val_loss: 32451548.0000\n","Epoch [4080], val_loss: 32950588.0000\n","Epoch [4100], val_loss: 33462792.0000\n","Epoch [4120], val_loss: 33884004.0000\n","Epoch [4140], val_loss: 32738850.0000\n","Epoch [4160], val_loss: 33634388.0000\n","Epoch [4180], val_loss: 34411992.0000\n","Epoch [4200], val_loss: 32873410.0000\n","Epoch [4220], val_loss: 33695376.0000\n","Epoch [4240], val_loss: 34032956.0000\n","Epoch [4260], val_loss: 33815780.0000\n","Epoch [4280], val_loss: 33905692.0000\n","Epoch [4300], val_loss: 33267508.0000\n","Epoch [4320], val_loss: 32470732.0000\n","Epoch [4340], val_loss: 32700826.0000\n","Epoch [4360], val_loss: 33147160.0000\n","Epoch [4380], val_loss: 34110420.0000\n","Epoch [4400], val_loss: 33090260.0000\n","Epoch [4420], val_loss: 34697712.0000\n","Epoch [4440], val_loss: 34280056.0000\n","Epoch [4460], val_loss: 33802156.0000\n","Epoch [4480], val_loss: 32715672.0000\n","Epoch [4500], val_loss: 32396326.0000\n","Epoch [4520], val_loss: 35869776.0000\n","Epoch [4540], val_loss: 33317684.0000\n","Epoch [4560], val_loss: 34775712.0000\n","Epoch [4580], val_loss: 33127816.0000\n","Epoch [4600], val_loss: 34942816.0000\n","Epoch [4620], val_loss: 33693212.0000\n","Epoch [4640], val_loss: 35367264.0000\n","Epoch [4660], val_loss: 33302882.0000\n","Epoch [4680], val_loss: 33238696.0000\n","Epoch [4700], val_loss: 33294124.0000\n","Epoch [4720], val_loss: 32801108.0000\n","Epoch [4740], val_loss: 35759516.0000\n","Epoch [4760], val_loss: 32685196.0000\n","Epoch [4780], val_loss: 33776840.0000\n","Epoch [4800], val_loss: 33041224.0000\n","Epoch [4820], val_loss: 34405816.0000\n","Epoch [4840], val_loss: 32730820.0000\n","Epoch [4860], val_loss: 35056424.0000\n","Epoch [4880], val_loss: 35318240.0000\n","Epoch [4900], val_loss: 32741840.0000\n","Epoch [4920], val_loss: 33183348.0000\n","Epoch [4940], val_loss: 33260834.0000\n","Epoch [4960], val_loss: 34485536.0000\n","Epoch [4980], val_loss: 36238212.0000\n","Epoch [5000], val_loss: 32924692.0000\n"]}],"source":["epochs = 5000\n","lr = 5e-5\n","history2 = fit(epochs, lr, model, train_loader, val_loader)"]},{"cell_type":"code","execution_count":210,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103156,"status":"ok","timestamp":1649779612586,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"},"user_tz":-60},"id":"dqthJ9s5-yMX","outputId":"59641e83-e336-4984-c874-10355c921da8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [20], val_loss: 33509468.0000\n","Epoch [40], val_loss: 33188328.0000\n","Epoch [60], val_loss: 33308388.0000\n","Epoch [80], val_loss: 33287300.0000\n","Epoch [100], val_loss: 33151714.0000\n","Epoch [120], val_loss: 33334496.0000\n","Epoch [140], val_loss: 33226266.0000\n","Epoch [160], val_loss: 33239552.0000\n","Epoch [180], val_loss: 33185076.0000\n","Epoch [200], val_loss: 33614564.0000\n","Epoch [220], val_loss: 33958232.0000\n","Epoch [240], val_loss: 33609236.0000\n","Epoch [260], val_loss: 33599832.0000\n","Epoch [280], val_loss: 33488306.0000\n","Epoch [300], val_loss: 33413060.0000\n","Epoch [320], val_loss: 33223122.0000\n","Epoch [340], val_loss: 33387118.0000\n","Epoch [360], val_loss: 33139688.0000\n","Epoch [380], val_loss: 33638832.0000\n","Epoch [400], val_loss: 33497560.0000\n","Epoch [420], val_loss: 33132984.0000\n","Epoch [440], val_loss: 33419548.0000\n","Epoch [460], val_loss: 33205254.0000\n","Epoch [480], val_loss: 33346572.0000\n","Epoch [500], val_loss: 33604672.0000\n","Epoch [520], val_loss: 33132148.0000\n","Epoch [540], val_loss: 33461936.0000\n","Epoch [560], val_loss: 33361730.0000\n","Epoch [580], val_loss: 33366512.0000\n","Epoch [600], val_loss: 33091200.0000\n","Epoch [620], val_loss: 33440600.0000\n","Epoch [640], val_loss: 33377872.0000\n","Epoch [660], val_loss: 32946784.0000\n","Epoch [680], val_loss: 33537658.0000\n","Epoch [700], val_loss: 33556928.0000\n","Epoch [720], val_loss: 33173460.0000\n","Epoch [740], val_loss: 33256230.0000\n","Epoch [760], val_loss: 33594220.0000\n","Epoch [780], val_loss: 33517006.0000\n","Epoch [800], val_loss: 33173114.0000\n","Epoch [820], val_loss: 33577816.0000\n","Epoch [840], val_loss: 33191936.0000\n","Epoch [860], val_loss: 33252520.0000\n","Epoch [880], val_loss: 33332320.0000\n","Epoch [900], val_loss: 33636256.0000\n","Epoch [920], val_loss: 33094690.0000\n","Epoch [940], val_loss: 33458524.0000\n","Epoch [960], val_loss: 33071674.0000\n","Epoch [980], val_loss: 33443284.0000\n","Epoch [1000], val_loss: 32921096.0000\n","Epoch [1020], val_loss: 33391612.0000\n","Epoch [1040], val_loss: 33333088.0000\n","Epoch [1060], val_loss: 33367790.0000\n","Epoch [1080], val_loss: 33283260.0000\n","Epoch [1100], val_loss: 33594892.0000\n","Epoch [1120], val_loss: 33291872.0000\n","Epoch [1140], val_loss: 33364468.0000\n","Epoch [1160], val_loss: 33494000.0000\n","Epoch [1180], val_loss: 33051452.0000\n","Epoch [1200], val_loss: 33890864.0000\n","Epoch [1220], val_loss: 33265936.0000\n","Epoch [1240], val_loss: 33368632.0000\n","Epoch [1260], val_loss: 33136834.0000\n","Epoch [1280], val_loss: 33229920.0000\n","Epoch [1300], val_loss: 33492196.0000\n","Epoch [1320], val_loss: 33393892.0000\n","Epoch [1340], val_loss: 33904664.0000\n","Epoch [1360], val_loss: 33378868.0000\n","Epoch [1380], val_loss: 33531928.0000\n","Epoch [1400], val_loss: 33436528.0000\n","Epoch [1420], val_loss: 33073282.0000\n","Epoch [1440], val_loss: 33290376.0000\n","Epoch [1460], val_loss: 33565160.0000\n","Epoch [1480], val_loss: 33245972.0000\n","Epoch [1500], val_loss: 33361988.0000\n","Epoch [1520], val_loss: 33171168.0000\n","Epoch [1540], val_loss: 33783528.0000\n","Epoch [1560], val_loss: 33421956.0000\n","Epoch [1580], val_loss: 33415600.0000\n","Epoch [1600], val_loss: 33319200.0000\n","Epoch [1620], val_loss: 33266962.0000\n","Epoch [1640], val_loss: 33503916.0000\n","Epoch [1660], val_loss: 32972080.0000\n","Epoch [1680], val_loss: 33540556.0000\n","Epoch [1700], val_loss: 33623288.0000\n","Epoch [1720], val_loss: 33417966.0000\n","Epoch [1740], val_loss: 33603520.0000\n","Epoch [1760], val_loss: 33032126.0000\n","Epoch [1780], val_loss: 33303820.0000\n","Epoch [1800], val_loss: 33209584.0000\n","Epoch [1820], val_loss: 33373396.0000\n","Epoch [1840], val_loss: 33369908.0000\n","Epoch [1860], val_loss: 33453998.0000\n","Epoch [1880], val_loss: 33603136.0000\n","Epoch [1900], val_loss: 33186100.0000\n","Epoch [1920], val_loss: 33041284.0000\n","Epoch [1940], val_loss: 33308960.0000\n","Epoch [1960], val_loss: 33170080.0000\n","Epoch [1980], val_loss: 33496538.0000\n","Epoch [2000], val_loss: 33484744.0000\n","Epoch [2020], val_loss: 33938584.0000\n","Epoch [2040], val_loss: 33404332.0000\n","Epoch [2060], val_loss: 33212844.0000\n","Epoch [2080], val_loss: 33296572.0000\n","Epoch [2100], val_loss: 33400416.0000\n","Epoch [2120], val_loss: 33684872.0000\n","Epoch [2140], val_loss: 33156872.0000\n","Epoch [2160], val_loss: 33476212.0000\n","Epoch [2180], val_loss: 33365600.0000\n","Epoch [2200], val_loss: 33362126.0000\n","Epoch [2220], val_loss: 33114972.0000\n","Epoch [2240], val_loss: 33184170.0000\n","Epoch [2260], val_loss: 33487072.0000\n","Epoch [2280], val_loss: 33169234.0000\n","Epoch [2300], val_loss: 33063152.0000\n","Epoch [2320], val_loss: 33085924.0000\n","Epoch [2340], val_loss: 33691960.0000\n","Epoch [2360], val_loss: 33115756.0000\n","Epoch [2380], val_loss: 33432052.0000\n","Epoch [2400], val_loss: 33258316.0000\n","Epoch [2420], val_loss: 33308292.0000\n","Epoch [2440], val_loss: 33542976.0000\n","Epoch [2460], val_loss: 33258412.0000\n","Epoch [2480], val_loss: 33330810.0000\n","Epoch [2500], val_loss: 33277652.0000\n","Epoch [2520], val_loss: 33408448.0000\n","Epoch [2540], val_loss: 33095524.0000\n","Epoch [2560], val_loss: 33330532.0000\n","Epoch [2580], val_loss: 33559788.0000\n","Epoch [2600], val_loss: 33839296.0000\n","Epoch [2620], val_loss: 33423476.0000\n","Epoch [2640], val_loss: 33207312.0000\n","Epoch [2660], val_loss: 33349058.0000\n","Epoch [2680], val_loss: 33510098.0000\n","Epoch [2700], val_loss: 33939036.0000\n","Epoch [2720], val_loss: 32917350.0000\n","Epoch [2740], val_loss: 33164888.0000\n","Epoch [2760], val_loss: 33264318.0000\n","Epoch [2780], val_loss: 33320450.0000\n","Epoch [2800], val_loss: 33614920.0000\n","Epoch [2820], val_loss: 33019792.0000\n","Epoch [2840], val_loss: 33192684.0000\n","Epoch [2860], val_loss: 33115106.0000\n","Epoch [2880], val_loss: 33093352.0000\n","Epoch [2900], val_loss: 33602700.0000\n","Epoch [2920], val_loss: 33192560.0000\n","Epoch [2940], val_loss: 33198888.0000\n","Epoch [2960], val_loss: 33379804.0000\n","Epoch [2980], val_loss: 33392246.0000\n","Epoch [3000], val_loss: 33150658.0000\n","Epoch [3020], val_loss: 33670040.0000\n","Epoch [3040], val_loss: 33608012.0000\n","Epoch [3060], val_loss: 33307348.0000\n","Epoch [3080], val_loss: 33936952.0000\n","Epoch [3100], val_loss: 33380836.0000\n","Epoch [3120], val_loss: 33294608.0000\n","Epoch [3140], val_loss: 33344228.0000\n","Epoch [3160], val_loss: 33245860.0000\n","Epoch [3180], val_loss: 33310496.0000\n","Epoch [3200], val_loss: 32960440.0000\n","Epoch [3220], val_loss: 32987320.0000\n","Epoch [3240], val_loss: 33893992.0000\n","Epoch [3260], val_loss: 33131784.0000\n","Epoch [3280], val_loss: 33411484.0000\n","Epoch [3300], val_loss: 33138432.0000\n","Epoch [3320], val_loss: 33097400.0000\n","Epoch [3340], val_loss: 33238048.0000\n","Epoch [3360], val_loss: 33035546.0000\n","Epoch [3380], val_loss: 33076898.0000\n","Epoch [3400], val_loss: 33438438.0000\n","Epoch [3420], val_loss: 33560004.0000\n","Epoch [3440], val_loss: 33498246.0000\n","Epoch [3460], val_loss: 33192876.0000\n","Epoch [3480], val_loss: 33488056.0000\n","Epoch [3500], val_loss: 33821336.0000\n","Epoch [3520], val_loss: 33185664.0000\n","Epoch [3540], val_loss: 33318036.0000\n","Epoch [3560], val_loss: 32967674.0000\n","Epoch [3580], val_loss: 33166078.0000\n","Epoch [3600], val_loss: 33300816.0000\n","Epoch [3620], val_loss: 33187188.0000\n","Epoch [3640], val_loss: 33430848.0000\n","Epoch [3660], val_loss: 33130500.0000\n","Epoch [3680], val_loss: 33612844.0000\n","Epoch [3700], val_loss: 33081952.0000\n","Epoch [3720], val_loss: 33354348.0000\n","Epoch [3740], val_loss: 33217394.0000\n","Epoch [3760], val_loss: 33294480.0000\n","Epoch [3780], val_loss: 33358040.0000\n","Epoch [3800], val_loss: 33311056.0000\n","Epoch [3820], val_loss: 33263106.0000\n","Epoch [3840], val_loss: 33128508.0000\n","Epoch [3860], val_loss: 33085840.0000\n","Epoch [3880], val_loss: 33343964.0000\n","Epoch [3900], val_loss: 33507888.0000\n","Epoch [3920], val_loss: 33418388.0000\n","Epoch [3940], val_loss: 33238784.0000\n","Epoch [3960], val_loss: 33190574.0000\n","Epoch [3980], val_loss: 33513318.0000\n","Epoch [4000], val_loss: 33348480.0000\n","Epoch [4020], val_loss: 33014432.0000\n","Epoch [4040], val_loss: 33063052.0000\n","Epoch [4060], val_loss: 32817912.0000\n","Epoch [4080], val_loss: 33051424.0000\n","Epoch [4100], val_loss: 33112164.0000\n","Epoch [4120], val_loss: 32873554.0000\n","Epoch [4140], val_loss: 33593672.0000\n","Epoch [4160], val_loss: 33195404.0000\n","Epoch [4180], val_loss: 33338460.0000\n","Epoch [4200], val_loss: 33641756.0000\n","Epoch [4220], val_loss: 33067976.0000\n","Epoch [4240], val_loss: 33317448.0000\n","Epoch [4260], val_loss: 33269296.0000\n","Epoch [4280], val_loss: 33175136.0000\n","Epoch [4300], val_loss: 33169940.0000\n","Epoch [4320], val_loss: 33270624.0000\n","Epoch [4340], val_loss: 33682548.0000\n","Epoch [4360], val_loss: 32914320.0000\n","Epoch [4380], val_loss: 33652484.0000\n","Epoch [4400], val_loss: 33163280.0000\n","Epoch [4420], val_loss: 33274452.0000\n","Epoch [4440], val_loss: 33278244.0000\n","Epoch [4460], val_loss: 33090856.0000\n","Epoch [4480], val_loss: 33278756.0000\n","Epoch [4500], val_loss: 33137240.0000\n","Epoch [4520], val_loss: 33228798.0000\n","Epoch [4540], val_loss: 33276284.0000\n","Epoch [4560], val_loss: 33828028.0000\n","Epoch [4580], val_loss: 33142940.0000\n","Epoch [4600], val_loss: 33386260.0000\n","Epoch [4620], val_loss: 33407382.0000\n","Epoch [4640], val_loss: 33549196.0000\n","Epoch [4660], val_loss: 33116604.0000\n","Epoch [4680], val_loss: 33535208.0000\n","Epoch [4700], val_loss: 33165912.0000\n","Epoch [4720], val_loss: 33223584.0000\n","Epoch [4740], val_loss: 33013350.0000\n","Epoch [4760], val_loss: 33079320.0000\n","Epoch [4780], val_loss: 33049628.0000\n","Epoch [4800], val_loss: 33677744.0000\n","Epoch [4820], val_loss: 33277088.0000\n","Epoch [4840], val_loss: 33291452.0000\n","Epoch [4860], val_loss: 33259040.0000\n","Epoch [4880], val_loss: 33108088.0000\n","Epoch [4900], val_loss: 33118184.0000\n","Epoch [4920], val_loss: 33332408.0000\n","Epoch [4940], val_loss: 33708604.0000\n","Epoch [4960], val_loss: 32993102.0000\n","Epoch [4980], val_loss: 33582104.0000\n","Epoch [5000], val_loss: 33183988.0000\n"]}],"source":["epochs = 5000\n","lr = 1e-5\n","history3 = fit(epochs, lr, model, train_loader, val_loader)"]},{"cell_type":"code","execution_count":211,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q0r7uKEM-yMX","executionInfo":{"status":"ok","timestamp":1649779711484,"user_tz":-60,"elapsed":98923,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}},"outputId":"834aec87-07d1-444b-d3a9-be21fc43b62c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [20], val_loss: 33160914.0000\n","Epoch [40], val_loss: 33150516.0000\n","Epoch [60], val_loss: 33280320.0000\n","Epoch [80], val_loss: 33157740.0000\n","Epoch [100], val_loss: 33175752.0000\n","Epoch [120], val_loss: 33322272.0000\n","Epoch [140], val_loss: 33181816.0000\n","Epoch [160], val_loss: 33294016.0000\n","Epoch [180], val_loss: 33258182.0000\n","Epoch [200], val_loss: 33424232.0000\n","Epoch [220], val_loss: 33140624.0000\n","Epoch [240], val_loss: 33180268.0000\n","Epoch [260], val_loss: 33288824.0000\n","Epoch [280], val_loss: 33261338.0000\n","Epoch [300], val_loss: 33255448.0000\n","Epoch [320], val_loss: 33100928.0000\n","Epoch [340], val_loss: 33112172.0000\n","Epoch [360], val_loss: 33226698.0000\n","Epoch [380], val_loss: 33283332.0000\n","Epoch [400], val_loss: 33276600.0000\n","Epoch [420], val_loss: 33252830.0000\n","Epoch [440], val_loss: 33186370.0000\n","Epoch [460], val_loss: 33214646.0000\n","Epoch [480], val_loss: 33190840.0000\n","Epoch [500], val_loss: 33318462.0000\n","Epoch [520], val_loss: 33186500.0000\n","Epoch [540], val_loss: 33323586.0000\n","Epoch [560], val_loss: 33258308.0000\n","Epoch [580], val_loss: 33192140.0000\n","Epoch [600], val_loss: 33224000.0000\n","Epoch [620], val_loss: 33178408.0000\n","Epoch [640], val_loss: 33199462.0000\n","Epoch [660], val_loss: 33255336.0000\n","Epoch [680], val_loss: 33162120.0000\n","Epoch [700], val_loss: 33081028.0000\n","Epoch [720], val_loss: 33158858.0000\n","Epoch [740], val_loss: 33225346.0000\n","Epoch [760], val_loss: 33093362.0000\n","Epoch [780], val_loss: 33132302.0000\n","Epoch [800], val_loss: 33157332.0000\n","Epoch [820], val_loss: 33195582.0000\n","Epoch [840], val_loss: 33291284.0000\n","Epoch [860], val_loss: 33292816.0000\n","Epoch [880], val_loss: 33170482.0000\n","Epoch [900], val_loss: 33412676.0000\n","Epoch [920], val_loss: 33155640.0000\n","Epoch [940], val_loss: 33317066.0000\n","Epoch [960], val_loss: 33352518.0000\n","Epoch [980], val_loss: 33221608.0000\n","Epoch [1000], val_loss: 33331456.0000\n","Epoch [1020], val_loss: 33165468.0000\n","Epoch [1040], val_loss: 33063016.0000\n","Epoch [1060], val_loss: 33151714.0000\n","Epoch [1080], val_loss: 33262332.0000\n","Epoch [1100], val_loss: 33222836.0000\n","Epoch [1120], val_loss: 33413516.0000\n","Epoch [1140], val_loss: 33177828.0000\n","Epoch [1160], val_loss: 33182020.0000\n","Epoch [1180], val_loss: 33239696.0000\n","Epoch [1200], val_loss: 33228980.0000\n","Epoch [1220], val_loss: 33285300.0000\n","Epoch [1240], val_loss: 33220272.0000\n","Epoch [1260], val_loss: 33211960.0000\n","Epoch [1280], val_loss: 33287680.0000\n","Epoch [1300], val_loss: 33177248.0000\n","Epoch [1320], val_loss: 33248056.0000\n","Epoch [1340], val_loss: 33301832.0000\n","Epoch [1360], val_loss: 33369134.0000\n","Epoch [1380], val_loss: 33371132.0000\n","Epoch [1400], val_loss: 33185764.0000\n","Epoch [1420], val_loss: 33289020.0000\n","Epoch [1440], val_loss: 33278174.0000\n","Epoch [1460], val_loss: 33226192.0000\n","Epoch [1480], val_loss: 33312264.0000\n","Epoch [1500], val_loss: 33250392.0000\n","Epoch [1520], val_loss: 33262808.0000\n","Epoch [1540], val_loss: 33148820.0000\n","Epoch [1560], val_loss: 33233340.0000\n","Epoch [1580], val_loss: 33267128.0000\n","Epoch [1600], val_loss: 33199552.0000\n","Epoch [1620], val_loss: 33267728.0000\n","Epoch [1640], val_loss: 33172848.0000\n","Epoch [1660], val_loss: 33180476.0000\n","Epoch [1680], val_loss: 33309928.0000\n","Epoch [1700], val_loss: 33333044.0000\n","Epoch [1720], val_loss: 33235196.0000\n","Epoch [1740], val_loss: 33329224.0000\n","Epoch [1760], val_loss: 33251280.0000\n","Epoch [1780], val_loss: 33257434.0000\n","Epoch [1800], val_loss: 33364894.0000\n","Epoch [1820], val_loss: 33441472.0000\n","Epoch [1840], val_loss: 33273308.0000\n","Epoch [1860], val_loss: 33171028.0000\n","Epoch [1880], val_loss: 33333844.0000\n","Epoch [1900], val_loss: 33273016.0000\n","Epoch [1920], val_loss: 33147258.0000\n","Epoch [1940], val_loss: 33291700.0000\n","Epoch [1960], val_loss: 33123672.0000\n","Epoch [1980], val_loss: 33115620.0000\n","Epoch [2000], val_loss: 33069880.0000\n","Epoch [2020], val_loss: 33172180.0000\n","Epoch [2040], val_loss: 33262322.0000\n","Epoch [2060], val_loss: 33218568.0000\n","Epoch [2080], val_loss: 33295972.0000\n","Epoch [2100], val_loss: 33189478.0000\n","Epoch [2120], val_loss: 33299922.0000\n","Epoch [2140], val_loss: 33334796.0000\n","Epoch [2160], val_loss: 33189618.0000\n","Epoch [2180], val_loss: 33350116.0000\n","Epoch [2200], val_loss: 33218818.0000\n","Epoch [2220], val_loss: 33171860.0000\n","Epoch [2240], val_loss: 33268274.0000\n","Epoch [2260], val_loss: 33243054.0000\n","Epoch [2280], val_loss: 33110860.0000\n","Epoch [2300], val_loss: 33231760.0000\n","Epoch [2320], val_loss: 33175904.0000\n","Epoch [2340], val_loss: 33271408.0000\n","Epoch [2360], val_loss: 33395698.0000\n","Epoch [2380], val_loss: 33270464.0000\n","Epoch [2400], val_loss: 33181612.0000\n","Epoch [2420], val_loss: 33245780.0000\n","Epoch [2440], val_loss: 33198692.0000\n","Epoch [2460], val_loss: 33174544.0000\n","Epoch [2480], val_loss: 33139966.0000\n","Epoch [2500], val_loss: 33420036.0000\n","Epoch [2520], val_loss: 33285228.0000\n","Epoch [2540], val_loss: 33276096.0000\n","Epoch [2560], val_loss: 33313136.0000\n","Epoch [2580], val_loss: 33224016.0000\n","Epoch [2600], val_loss: 33160996.0000\n","Epoch [2620], val_loss: 33100506.0000\n","Epoch [2640], val_loss: 33334284.0000\n","Epoch [2660], val_loss: 33283652.0000\n","Epoch [2680], val_loss: 33355660.0000\n","Epoch [2700], val_loss: 33097776.0000\n","Epoch [2720], val_loss: 33362364.0000\n","Epoch [2740], val_loss: 33349152.0000\n","Epoch [2760], val_loss: 33208480.0000\n","Epoch [2780], val_loss: 33274016.0000\n","Epoch [2800], val_loss: 33153638.0000\n","Epoch [2820], val_loss: 33307660.0000\n","Epoch [2840], val_loss: 33252332.0000\n","Epoch [2860], val_loss: 33192678.0000\n","Epoch [2880], val_loss: 33217918.0000\n","Epoch [2900], val_loss: 33317428.0000\n","Epoch [2920], val_loss: 33276720.0000\n","Epoch [2940], val_loss: 33268220.0000\n","Epoch [2960], val_loss: 33160892.0000\n","Epoch [2980], val_loss: 33313724.0000\n","Epoch [3000], val_loss: 33149104.0000\n","Epoch [3020], val_loss: 33167640.0000\n","Epoch [3040], val_loss: 33172392.0000\n","Epoch [3060], val_loss: 33095492.0000\n","Epoch [3080], val_loss: 33173796.0000\n","Epoch [3100], val_loss: 33328398.0000\n","Epoch [3120], val_loss: 33271408.0000\n","Epoch [3140], val_loss: 33186200.0000\n","Epoch [3160], val_loss: 33124936.0000\n","Epoch [3180], val_loss: 33248032.0000\n","Epoch [3200], val_loss: 33299132.0000\n","Epoch [3220], val_loss: 33157256.0000\n","Epoch [3240], val_loss: 33224158.0000\n","Epoch [3260], val_loss: 33304720.0000\n","Epoch [3280], val_loss: 33297616.0000\n","Epoch [3300], val_loss: 33389708.0000\n","Epoch [3320], val_loss: 33247330.0000\n","Epoch [3340], val_loss: 33214496.0000\n","Epoch [3360], val_loss: 33159638.0000\n","Epoch [3380], val_loss: 33247418.0000\n","Epoch [3400], val_loss: 33235614.0000\n","Epoch [3420], val_loss: 33209556.0000\n","Epoch [3440], val_loss: 33282124.0000\n","Epoch [3460], val_loss: 33186444.0000\n","Epoch [3480], val_loss: 33265108.0000\n","Epoch [3500], val_loss: 33312460.0000\n","Epoch [3520], val_loss: 33031660.0000\n","Epoch [3540], val_loss: 33121848.0000\n","Epoch [3560], val_loss: 33263470.0000\n","Epoch [3580], val_loss: 33305484.0000\n","Epoch [3600], val_loss: 33232328.0000\n","Epoch [3620], val_loss: 33239634.0000\n","Epoch [3640], val_loss: 33229196.0000\n","Epoch [3660], val_loss: 33164552.0000\n","Epoch [3680], val_loss: 33032980.0000\n","Epoch [3700], val_loss: 33241904.0000\n","Epoch [3720], val_loss: 33307188.0000\n","Epoch [3740], val_loss: 33134064.0000\n","Epoch [3760], val_loss: 33268156.0000\n","Epoch [3780], val_loss: 33104720.0000\n","Epoch [3800], val_loss: 33169408.0000\n","Epoch [3820], val_loss: 33246998.0000\n","Epoch [3840], val_loss: 33203020.0000\n","Epoch [3860], val_loss: 33276858.0000\n","Epoch [3880], val_loss: 33162798.0000\n","Epoch [3900], val_loss: 33272148.0000\n","Epoch [3920], val_loss: 33363380.0000\n","Epoch [3940], val_loss: 33161718.0000\n","Epoch [3960], val_loss: 33207574.0000\n","Epoch [3980], val_loss: 33082048.0000\n","Epoch [4000], val_loss: 33310860.0000\n","Epoch [4020], val_loss: 33214664.0000\n","Epoch [4040], val_loss: 33170158.0000\n","Epoch [4060], val_loss: 33155636.0000\n","Epoch [4080], val_loss: 33223038.0000\n","Epoch [4100], val_loss: 33227446.0000\n","Epoch [4120], val_loss: 33230244.0000\n","Epoch [4140], val_loss: 33303436.0000\n","Epoch [4160], val_loss: 33239456.0000\n","Epoch [4180], val_loss: 33257168.0000\n","Epoch [4200], val_loss: 33165048.0000\n","Epoch [4220], val_loss: 33258986.0000\n","Epoch [4240], val_loss: 33244424.0000\n","Epoch [4260], val_loss: 33411484.0000\n","Epoch [4280], val_loss: 33207920.0000\n","Epoch [4300], val_loss: 33187768.0000\n","Epoch [4320], val_loss: 33269472.0000\n","Epoch [4340], val_loss: 33022838.0000\n","Epoch [4360], val_loss: 33176184.0000\n","Epoch [4380], val_loss: 33190824.0000\n","Epoch [4400], val_loss: 33277316.0000\n","Epoch [4420], val_loss: 33209264.0000\n","Epoch [4440], val_loss: 33296968.0000\n","Epoch [4460], val_loss: 33238470.0000\n","Epoch [4480], val_loss: 33139028.0000\n","Epoch [4500], val_loss: 33370504.0000\n","Epoch [4520], val_loss: 33219196.0000\n","Epoch [4540], val_loss: 33231804.0000\n","Epoch [4560], val_loss: 33205424.0000\n","Epoch [4580], val_loss: 33251000.0000\n","Epoch [4600], val_loss: 33186464.0000\n","Epoch [4620], val_loss: 33230684.0000\n","Epoch [4640], val_loss: 33126026.0000\n","Epoch [4660], val_loss: 33343608.0000\n","Epoch [4680], val_loss: 33296280.0000\n","Epoch [4700], val_loss: 33217460.0000\n","Epoch [4720], val_loss: 33278284.0000\n","Epoch [4740], val_loss: 33329922.0000\n","Epoch [4760], val_loss: 33237736.0000\n","Epoch [4780], val_loss: 33114628.0000\n","Epoch [4800], val_loss: 33127780.0000\n","Epoch [4820], val_loss: 33213686.0000\n","Epoch [4840], val_loss: 33138242.0000\n","Epoch [4860], val_loss: 33165696.0000\n","Epoch [4880], val_loss: 33055220.0000\n","Epoch [4900], val_loss: 33347204.0000\n","Epoch [4920], val_loss: 33120312.0000\n","Epoch [4940], val_loss: 33124320.0000\n","Epoch [4960], val_loss: 33132186.0000\n","Epoch [4980], val_loss: 33279432.0000\n","Epoch [5000], val_loss: 33193044.0000\n"]}],"source":["epochs = 5000\n","lr = 5e-6\n","history4 = fit(epochs, lr, model, train_loader, val_loader)"]},{"cell_type":"code","execution_count":212,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCJ9sl2T-yMX","executionInfo":{"status":"ok","timestamp":1649779814230,"user_tz":-60,"elapsed":102765,"user":{"displayName":"Adejumo Daniel","userId":"02925977078148845759"}},"outputId":"0008526d-7a0c-4dab-f195-6f4b9afd566f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [20], val_loss: 33218900.0000\n","Epoch [40], val_loss: 33236036.0000\n","Epoch [60], val_loss: 33211686.0000\n","Epoch [80], val_loss: 33224830.0000\n","Epoch [100], val_loss: 33219368.0000\n","Epoch [120], val_loss: 33214908.0000\n","Epoch [140], val_loss: 33229396.0000\n","Epoch [160], val_loss: 33214092.0000\n","Epoch [180], val_loss: 33219882.0000\n","Epoch [200], val_loss: 33204264.0000\n","Epoch [220], val_loss: 33200362.0000\n","Epoch [240], val_loss: 33222504.0000\n","Epoch [260], val_loss: 33213128.0000\n","Epoch [280], val_loss: 33205508.0000\n","Epoch [300], val_loss: 33223538.0000\n","Epoch [320], val_loss: 33213832.0000\n","Epoch [340], val_loss: 33199756.0000\n","Epoch [360], val_loss: 33207196.0000\n","Epoch [380], val_loss: 33203424.0000\n","Epoch [400], val_loss: 33217096.0000\n","Epoch [420], val_loss: 33212090.0000\n","Epoch [440], val_loss: 33214472.0000\n","Epoch [460], val_loss: 33204892.0000\n","Epoch [480], val_loss: 33230596.0000\n","Epoch [500], val_loss: 33209672.0000\n","Epoch [520], val_loss: 33213322.0000\n","Epoch [540], val_loss: 33230104.0000\n","Epoch [560], val_loss: 33202734.0000\n","Epoch [580], val_loss: 33214444.0000\n","Epoch [600], val_loss: 33213350.0000\n","Epoch [620], val_loss: 33215916.0000\n","Epoch [640], val_loss: 33222456.0000\n","Epoch [660], val_loss: 33221804.0000\n","Epoch [680], val_loss: 33230960.0000\n","Epoch [700], val_loss: 33226574.0000\n","Epoch [720], val_loss: 33254010.0000\n","Epoch [740], val_loss: 33218492.0000\n","Epoch [760], val_loss: 33209628.0000\n","Epoch [780], val_loss: 33212426.0000\n","Epoch [800], val_loss: 33215128.0000\n","Epoch [820], val_loss: 33212216.0000\n","Epoch [840], val_loss: 33206528.0000\n","Epoch [860], val_loss: 33209716.0000\n","Epoch [880], val_loss: 33202816.0000\n","Epoch [900], val_loss: 33213800.0000\n","Epoch [920], val_loss: 33213236.0000\n","Epoch [940], val_loss: 33211222.0000\n","Epoch [960], val_loss: 33221560.0000\n","Epoch [980], val_loss: 33214610.0000\n","Epoch [1000], val_loss: 33228268.0000\n","Epoch [1020], val_loss: 33194698.0000\n","Epoch [1040], val_loss: 33186286.0000\n","Epoch [1060], val_loss: 33234268.0000\n","Epoch [1080], val_loss: 33225624.0000\n","Epoch [1100], val_loss: 33214284.0000\n","Epoch [1120], val_loss: 33214176.0000\n","Epoch [1140], val_loss: 33198874.0000\n","Epoch [1160], val_loss: 33195068.0000\n","Epoch [1180], val_loss: 33207280.0000\n","Epoch [1200], val_loss: 33219234.0000\n","Epoch [1220], val_loss: 33223506.0000\n","Epoch [1240], val_loss: 33230228.0000\n","Epoch [1260], val_loss: 33207340.0000\n","Epoch [1280], val_loss: 33221828.0000\n","Epoch [1300], val_loss: 33204532.0000\n","Epoch [1320], val_loss: 33203126.0000\n","Epoch [1340], val_loss: 33214612.0000\n","Epoch [1360], val_loss: 33199602.0000\n","Epoch [1380], val_loss: 33209760.0000\n","Epoch [1400], val_loss: 33221988.0000\n","Epoch [1420], val_loss: 33215782.0000\n","Epoch [1440], val_loss: 33193476.0000\n","Epoch [1460], val_loss: 33197120.0000\n","Epoch [1480], val_loss: 33206004.0000\n","Epoch [1500], val_loss: 33235114.0000\n","Epoch [1520], val_loss: 33219348.0000\n","Epoch [1540], val_loss: 33220810.0000\n","Epoch [1560], val_loss: 33213314.0000\n","Epoch [1580], val_loss: 33204800.0000\n","Epoch [1600], val_loss: 33202880.0000\n","Epoch [1620], val_loss: 33223650.0000\n","Epoch [1640], val_loss: 33199636.0000\n","Epoch [1660], val_loss: 33207594.0000\n","Epoch [1680], val_loss: 33222296.0000\n","Epoch [1700], val_loss: 33216236.0000\n","Epoch [1720], val_loss: 33223980.0000\n","Epoch [1740], val_loss: 33214264.0000\n","Epoch [1760], val_loss: 33215408.0000\n","Epoch [1780], val_loss: 33220302.0000\n","Epoch [1800], val_loss: 33218648.0000\n","Epoch [1820], val_loss: 33225220.0000\n","Epoch [1840], val_loss: 33200332.0000\n","Epoch [1860], val_loss: 33217152.0000\n","Epoch [1880], val_loss: 33197552.0000\n","Epoch [1900], val_loss: 33213380.0000\n","Epoch [1920], val_loss: 33227404.0000\n","Epoch [1940], val_loss: 33209554.0000\n","Epoch [1960], val_loss: 33217120.0000\n","Epoch [1980], val_loss: 33229904.0000\n","Epoch [2000], val_loss: 33209854.0000\n","Epoch [2020], val_loss: 33210928.0000\n","Epoch [2040], val_loss: 33208936.0000\n","Epoch [2060], val_loss: 33213964.0000\n","Epoch [2080], val_loss: 33214118.0000\n","Epoch [2100], val_loss: 33203744.0000\n","Epoch [2120], val_loss: 33197020.0000\n","Epoch [2140], val_loss: 33188056.0000\n","Epoch [2160], val_loss: 33223448.0000\n","Epoch [2180], val_loss: 33204460.0000\n","Epoch [2200], val_loss: 33213540.0000\n","Epoch [2220], val_loss: 33229420.0000\n","Epoch [2240], val_loss: 33220504.0000\n","Epoch [2260], val_loss: 33226656.0000\n","Epoch [2280], val_loss: 33214206.0000\n","Epoch [2300], val_loss: 33223412.0000\n","Epoch [2320], val_loss: 33243080.0000\n","Epoch [2340], val_loss: 33227386.0000\n","Epoch [2360], val_loss: 33200162.0000\n","Epoch [2380], val_loss: 33199154.0000\n","Epoch [2400], val_loss: 33220852.0000\n","Epoch [2420], val_loss: 33201136.0000\n","Epoch [2440], val_loss: 33207248.0000\n","Epoch [2460], val_loss: 33206586.0000\n","Epoch [2480], val_loss: 33212818.0000\n","Epoch [2500], val_loss: 33213358.0000\n","Epoch [2520], val_loss: 33211166.0000\n","Epoch [2540], val_loss: 33221540.0000\n","Epoch [2560], val_loss: 33212220.0000\n","Epoch [2580], val_loss: 33197490.0000\n","Epoch [2600], val_loss: 33200418.0000\n","Epoch [2620], val_loss: 33232188.0000\n","Epoch [2640], val_loss: 33211998.0000\n","Epoch [2660], val_loss: 33217246.0000\n","Epoch [2680], val_loss: 33213860.0000\n","Epoch [2700], val_loss: 33215272.0000\n","Epoch [2720], val_loss: 33210666.0000\n","Epoch [2740], val_loss: 33203722.0000\n","Epoch [2760], val_loss: 33206188.0000\n","Epoch [2780], val_loss: 33212872.0000\n","Epoch [2800], val_loss: 33202300.0000\n","Epoch [2820], val_loss: 33215608.0000\n","Epoch [2840], val_loss: 33217276.0000\n","Epoch [2860], val_loss: 33210572.0000\n","Epoch [2880], val_loss: 33184784.0000\n","Epoch [2900], val_loss: 33201258.0000\n","Epoch [2920], val_loss: 33197812.0000\n","Epoch [2940], val_loss: 33211388.0000\n","Epoch [2960], val_loss: 33210020.0000\n","Epoch [2980], val_loss: 33193846.0000\n","Epoch [3000], val_loss: 33219260.0000\n","Epoch [3020], val_loss: 33216394.0000\n","Epoch [3040], val_loss: 33198610.0000\n","Epoch [3060], val_loss: 33197892.0000\n","Epoch [3080], val_loss: 33218490.0000\n","Epoch [3100], val_loss: 33211822.0000\n","Epoch [3120], val_loss: 33188382.0000\n","Epoch [3140], val_loss: 33203932.0000\n","Epoch [3160], val_loss: 33202296.0000\n","Epoch [3180], val_loss: 33208696.0000\n","Epoch [3200], val_loss: 33222396.0000\n","Epoch [3220], val_loss: 33200120.0000\n","Epoch [3240], val_loss: 33201508.0000\n","Epoch [3260], val_loss: 33195212.0000\n","Epoch [3280], val_loss: 33219370.0000\n","Epoch [3300], val_loss: 33198264.0000\n","Epoch [3320], val_loss: 33208450.0000\n","Epoch [3340], val_loss: 33212278.0000\n","Epoch [3360], val_loss: 33196316.0000\n","Epoch [3380], val_loss: 33209020.0000\n","Epoch [3400], val_loss: 33208236.0000\n","Epoch [3420], val_loss: 33177884.0000\n","Epoch [3440], val_loss: 33194300.0000\n","Epoch [3460], val_loss: 33219668.0000\n","Epoch [3480], val_loss: 33202300.0000\n","Epoch [3500], val_loss: 33198192.0000\n","Epoch [3520], val_loss: 33207592.0000\n","Epoch [3540], val_loss: 33211618.0000\n","Epoch [3560], val_loss: 33210768.0000\n","Epoch [3580], val_loss: 33204286.0000\n","Epoch [3600], val_loss: 33198122.0000\n","Epoch [3620], val_loss: 33187716.0000\n","Epoch [3640], val_loss: 33213280.0000\n","Epoch [3660], val_loss: 33205530.0000\n","Epoch [3680], val_loss: 33193292.0000\n","Epoch [3700], val_loss: 33201476.0000\n","Epoch [3720], val_loss: 33195368.0000\n","Epoch [3740], val_loss: 33202200.0000\n","Epoch [3760], val_loss: 33203490.0000\n","Epoch [3780], val_loss: 33206444.0000\n","Epoch [3800], val_loss: 33206064.0000\n","Epoch [3820], val_loss: 33208576.0000\n","Epoch [3840], val_loss: 33213668.0000\n","Epoch [3860], val_loss: 33211748.0000\n","Epoch [3880], val_loss: 33213184.0000\n","Epoch [3900], val_loss: 33204046.0000\n","Epoch [3920], val_loss: 33233640.0000\n","Epoch [3940], val_loss: 33210908.0000\n","Epoch [3960], val_loss: 33211480.0000\n","Epoch [3980], val_loss: 33221048.0000\n","Epoch [4000], val_loss: 33185932.0000\n","Epoch [4020], val_loss: 33216058.0000\n","Epoch [4040], val_loss: 33211656.0000\n","Epoch [4060], val_loss: 33204984.0000\n","Epoch [4080], val_loss: 33206228.0000\n","Epoch [4100], val_loss: 33208736.0000\n","Epoch [4120], val_loss: 33203004.0000\n","Epoch [4140], val_loss: 33209136.0000\n","Epoch [4160], val_loss: 33223928.0000\n","Epoch [4180], val_loss: 33198224.0000\n","Epoch [4200], val_loss: 33215176.0000\n","Epoch [4220], val_loss: 33218052.0000\n","Epoch [4240], val_loss: 33213184.0000\n","Epoch [4260], val_loss: 33222624.0000\n","Epoch [4280], val_loss: 33210888.0000\n","Epoch [4300], val_loss: 33227996.0000\n","Epoch [4320], val_loss: 33198880.0000\n","Epoch [4340], val_loss: 33197836.0000\n","Epoch [4360], val_loss: 33211444.0000\n","Epoch [4380], val_loss: 33195764.0000\n","Epoch [4400], val_loss: 33218412.0000\n","Epoch [4420], val_loss: 33214796.0000\n","Epoch [4440], val_loss: 33239476.0000\n","Epoch [4460], val_loss: 33209918.0000\n","Epoch [4480], val_loss: 33215684.0000\n","Epoch [4500], val_loss: 33190588.0000\n","Epoch [4520], val_loss: 33221420.0000\n","Epoch [4540], val_loss: 33208284.0000\n","Epoch [4560], val_loss: 33215414.0000\n","Epoch [4580], val_loss: 33215376.0000\n","Epoch [4600], val_loss: 33202180.0000\n","Epoch [4620], val_loss: 33212252.0000\n","Epoch [4640], val_loss: 33219320.0000\n","Epoch [4660], val_loss: 33207240.0000\n","Epoch [4680], val_loss: 33215416.0000\n","Epoch [4700], val_loss: 33214876.0000\n","Epoch [4720], val_loss: 33200452.0000\n","Epoch [4740], val_loss: 33205908.0000\n","Epoch [4760], val_loss: 33223196.0000\n","Epoch [4780], val_loss: 33223470.0000\n","Epoch [4800], val_loss: 33209764.0000\n","Epoch [4820], val_loss: 33209504.0000\n","Epoch [4840], val_loss: 33236654.0000\n","Epoch [4860], val_loss: 33209544.0000\n","Epoch [4880], val_loss: 33197992.0000\n","Epoch [4900], val_loss: 33201704.0000\n","Epoch [4920], val_loss: 33205660.0000\n","Epoch [4940], val_loss: 33211260.0000\n","Epoch [4960], val_loss: 33200408.0000\n","Epoch [4980], val_loss: 33213644.0000\n","Epoch [5000], val_loss: 33209380.0000\n"]}],"source":["epochs = 5000\n","lr = 1e-6\n","history5 = fit(epochs, lr, model, train_loader, val_loader)"]},{"cell_type":"markdown","metadata":{"id":"0DkSl4wy-yMX"},"source":["**Q12: What is the final validation loss of your model?**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"narrPXfS-yMY"},"outputs":[],"source":["val_loss = history5[-1][\"val_loss\"]"]},{"cell_type":"markdown","metadata":{"id":"kEz57_Sd-yMY"},"source":["Let's log the final validation loss to Jovian and commit the notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u5T3VGmN-yMZ"},"outputs":[],"source":["jovian.log_metrics(val_loss=val_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0XFYNGU-yMZ"},"outputs":[],"source":["jovian.commit(project=project_name, environment=None)"]},{"cell_type":"markdown","metadata":{"id":"wNph4HVX-yMZ"},"source":["Now scroll back up, re-initialize the model, and try different set of values for batch size, number of epochs, learning rate etc. Commit each experiment and use the \"Compare\" and \"View Diff\" options on Jovian to compare the different results."]},{"cell_type":"markdown","metadata":{"id":"GOVH_CUr-yMZ"},"source":["## Step 5: Make predictions using the trained model\n","\n","**Q13: Complete the following function definition to make predictions on a single input**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KPAAHNGJ-yMa"},"outputs":[],"source":["def predict_single(input, target, model):\n","    inputs = input.unsqueeze(0)\n","    predictions = ???                # fill this\n","    prediction = predictions[0].detach()\n","    print(\"Input:\", input)\n","    print(\"Target:\", target)\n","    print(\"Prediction:\", prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ibt57dYH-yMa"},"outputs":[],"source":["input, target = val_ds[0]\n","predict_single(input, target, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vkeva7W8-yMa"},"outputs":[],"source":["input, target = val_ds[10]\n","predict_single(input, target, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1XmlXCCX-yMa"},"outputs":[],"source":["input, target = val_ds[23]\n","predict_single(input, target, model)"]},{"cell_type":"markdown","metadata":{"id":"KaJNjCSu-yMb"},"source":["Are you happy with your model's predictions? Try to improve them further."]},{"cell_type":"markdown","metadata":{"id":"G4P-OEY8-yMb"},"source":["## (Optional) Step 6: Try another dataset & blog about it\n","\n","While this last step is optional for the submission of your assignment, we highly recommend that you do it. Try to replicate this notebook for a different linear regression or logistic regression problem. This will help solidify your understanding, and give you a chance to differentiate the generic patterns in machine learning from problem-specific details.You can use one of these starer notebooks (just change the dataset):\n","\n","- Linear regression (minimal): https://jovian.ai/aakashns/housing-linear-minimal\n","- Logistic regression (minimal): https://jovian.ai/aakashns/mnist-logistic-minimal\n","\n","Here are some sources to find good datasets:\n","\n","- https://lionbridge.ai/datasets/10-open-datasets-for-linear-regression/\n","- https://www.kaggle.com/rtatman/datasets-for-regression-analysis\n","- https://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table\n","- https://people.sc.fsu.edu/~jburkardt/datasets/regression/regression.html\n","- https://archive.ics.uci.edu/ml/datasets/wine+quality\n","- https://pytorch.org/docs/stable/torchvision/datasets.html\n","\n","We also recommend that you write a blog about your approach to the problem. Here is a suggested structure for your post (feel free to experiment with it):\n","\n","- Interesting title & subtitle\n","- Overview of what the blog covers (which dataset, linear regression or logistic regression, intro to PyTorch)\n","- Downloading & exploring the data\n","- Preparing the data for training\n","- Creating a model using PyTorch\n","- Training the model to fit the data\n","- Your thoughts on how to experiment with different hyperparmeters to reduce loss\n","- Making predictions using the model\n","\n","As with the previous assignment, you can [embed Juptyer notebook cells & outputs from Jovian](https://medium.com/jovianml/share-and-embed-jupyter-notebooks-online-with-jovian-ml-df709a03064e) into your blog. \n","\n","Don't forget to share your work on the forum: https://jovian.ai/forum/t/linear-regression-and-logistic-regression-notebooks-and-blog-posts/14039"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8olkGlM8-yMb","outputId":"eeae22a8-12b4-47d0-8e88-6daa956a08cd"},"outputs":[{"data":{"application/javascript":["window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[jovian] Attempting to save notebook..\u001b[0m\n","[jovian] Updating notebook \"aakashns/02-insurance-linear-regression\" on https://jovian.ai/\u001b[0m\n","[jovian] Uploading notebook..\u001b[0m\n","[jovian] Committed successfully! https://jovian.ai/aakashns/02-insurance-linear-regression\u001b[0m\n"]},{"data":{"application/javascript":["window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[jovian] Attempting to save notebook..\u001b[0m\n"]}],"source":["jovian.commit(project=project_name, environment=None)\n","jovian.commit(project=project_name, environment=None) # try again, kaggle fails sometimes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"etQ93g2i-yMc"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":["GOVH_CUr-yMZ","G4P-OEY8-yMb"],"name":"2. Insurance Cost Prediction.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}